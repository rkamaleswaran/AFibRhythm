{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "## Aug/15/17\n",
    "\n",
    "## Convolutional Neural Network on tensorflow-gpu\n",
    "%matplotlib inline\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    " \n",
    "# Dependency imports\n",
    "\n",
    "import time\n",
    "import os\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "import numpy as np\n",
    "import biosppy as bp\n",
    "\n",
    "## Load data\n",
    "ab = pd.read_csv('output_fullData_names_labels.csv', header=None)\n",
    "\n",
    "XLen = ab.shape[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:2: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate_ix\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "X0 = ab.ix[:,2: XLen ]\n",
    "X1 = X0.diff(axis=1)\n",
    "index = ab[0]\n",
    "y1 = ab[1]\n",
    "\n",
    "\n",
    "\n",
    "## Cast to 32bit\n",
    "y = y1.values.astype(np.int32)\n",
    "X = X1.values.astype(np.float32)\n",
    "\n",
    "## Set NaNs to 10e-6\n",
    "X[np.isnan(X)] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\sklearn\\preprocessing\\data.py:160: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\sklearn\\preprocessing\\data.py:177: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    }
   ],
   "source": [
    "## pip install pandas sklearn mataplotlib\n",
    "X_scaled = preprocessing.scale(X, axis=1)\n",
    "\n",
    "scaler = preprocessing.MinMaxScaler(feature_range=(-1, 1))\n",
    "scaler = scaler.fit(X.T)\n",
    "scaled_X = scaler.transform(X.T).T\n",
    "\n",
    "from sklearn.externals import joblib\n",
    "scaler_filename = \"scaler.save\"\n",
    "joblib.dump(scaler, scaler_filename) \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=1)\n",
    "\n",
    "#X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.05, random_state=1)\n",
    "\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "## Feature Scaling and split the data into training and test sets\n",
    "\n",
    "## Convert label to one hot format\n",
    "\n",
    "y_1Hot_train = to_categorical(y_train)\n",
    "y_1Hot_test = to_categorical(y_test)\n",
    "#y_1Hot_val = to_categorical(y_val)\n",
    "\n",
    "# y_1Hot_train = tf.one_hot(y_train, 4)\n",
    "# y_1Hot_test = tf.one_hot(y_test, 4)\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.3\n",
    "config.gpu_options.visible_device_list = \"0\"\n",
    "set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 4047, 1: 576, 2: 1970, 3: 229}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## count number of test samples\n",
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:11: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate_ix\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:12: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate_ix\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAEICAYAAACqMQjAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a18dea7d30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot(221)\n",
    "ax2 = fig.add_subplot(222)\n",
    "ax3 = fig.add_subplot(223)\n",
    "ax4 = fig.add_subplot(224)\n",
    "ax1.title.set_text('Raw Data')\n",
    "ax2.title.set_text('Diff Raw')\n",
    "ax3.title.set_text('Scaled Data')\n",
    "ax4.title.set_text('MinMax Scaled Data')\n",
    "\n",
    "ax1.plot(X0.ix[1])\n",
    "ax2.plot(X1.ix[1].diff())\n",
    "ax3.plot( X_scaled[1] )\n",
    "ax4.plot( scaled_X[1] )\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = X_train.reshape(X_train.shape[0], 1, X_train.shape[1])\n",
    "# X_test = X_test.reshape(X_test.shape[0], 1, X_test.shape[1])\n",
    "# X_val = X_val.reshape(X_val.shape[0], 1, X_val.shape[1])\n",
    "\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "#X_val = X_val.reshape(X_val.shape[0], X_val.shape[1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6822, 18286, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import itertools\n",
    "def plot_confusion_matrix(y_true,y_pred):\n",
    "    cm = confusion_matrix(y_true,y_pred)\n",
    "    true_labels = np.unique(y_true)\n",
    "    pred_labels = np.unique(y_pred)\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title(\"Confusion matrix\", fontsize=16)\n",
    "#     cbar = plt.colorbar(fraction=0.046, pad=0.04)\n",
    "#     cbar.set_label('Number of images', rotation=270, labelpad=30, fontsize=12)\n",
    "    xtick_marks = np.arange(len(true_labels))\n",
    "    ytick_marks = np.arange(len(pred_labels))\n",
    "    plt.xticks(xtick_marks, true_labels, rotation=90)\n",
    "    plt.yticks(ytick_marks,pred_labels)\n",
    "    \n",
    "    fmt = 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    \n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    \n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label', fontsize=14)\n",
    "    plt.xlabel('Predicted label', fontsize=14)\n",
    "    fig_size = plt.rcParams[\"figure.figsize\"]\n",
    "    fig_size[0] = 12\n",
    "    fig_size[1] = 12\n",
    "    plt.rcParams[\"figure.figsize\"] = fig_size\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(256, 18, kernel_initializer=\"uniform\", input_shape=(18286, 1))`\n",
      "  if __name__ == '__main__':\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:15: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(256, 18, kernel_initializer=\"uniform\")`\n",
      "  from ipykernel import kernelapp as app\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:21: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(256, 18, kernel_initializer=\"uniform\")`\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:27: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(128, 18, kernel_initializer=\"uniform\")`\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:33: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(128, 18, kernel_initializer=\"uniform\")`\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:39: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(64, 18, kernel_initializer=\"uniform\")`\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:45: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(64, 18, kernel_initializer=\"uniform\")`\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:51: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(32, 18, kernel_initializer=\"uniform\")`\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:57: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(32, 18, kernel_initializer=\"uniform\")`\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:62: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(16, 18, kernel_initializer=\"uniform\")`\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Conv1D, GlobalAveragePooling1D, MaxPooling1D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers import LSTM\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv1D(256, 18,  init='uniform', input_shape=X_train.shape[1:3]))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Conv1D(256, 18,  init='uniform'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Conv1D(256, 18,  init='uniform'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Conv1D(128, 18,  init='uniform'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Conv1D(128, 18,  init='uniform'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Conv1D(64, 18,  init='uniform'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Conv1D(64, 18,  init='uniform'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Conv1D(32, 18,  init='uniform'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Conv1D(32, 18,  init='uniform'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Conv1D(16, 18,  init='uniform'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(GlobalAveragePooling1D())\n",
    "#model.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "#model.add(LSTM(160, dropout=0.2, recurrent_dropout=0.2, return_sequences=True))\n",
    "\n",
    "#model.add(LSTM(4, dropout=0.2, recurrent_dropout=0.2, activation='softmax'))\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "# # Compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 18269, 256)        4864      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 18269, 256)        1024      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 18269, 256)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 9134, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 9134, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 9117, 256)         1179904   \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 9117, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 9117, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 4558, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4558, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 4541, 256)         1179904   \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 4541, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 4541, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 2270, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 2270, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 2253, 128)         589952    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 2253, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 2253, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 1126, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 1126, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 1109, 128)         295040    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 1109, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 1109, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 554, 128)          0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 554, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 537, 64)           147520    \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 537, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 537, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 268, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 268, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 251, 64)           73792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 251, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 251, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, 125, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 125, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 108, 32)           36896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 108, 32)           128       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 108, 32)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1 (None, 54, 32)            0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 54, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 37, 32)            18464     \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 37, 32)            128       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 37, 32)            0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 37, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_10 (Conv1D)           (None, 20, 16)            9232      \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 20, 16)            64        \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 20, 16)            0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 20, 16)            0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_1 ( (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4)                 68        \n",
      "=================================================================\n",
      "Total params: 3,540,564\n",
      "Trainable params: 3,538,100\n",
      "Non-trainable params: 2,464\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6139 samples, validate on 683 samples\n",
      "Epoch 1/3000\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "# serialize model to YAML\n",
    "\n",
    "class_weight = {0 : 1.,\n",
    "    1: 6.,\n",
    "    2: 2,\n",
    "    3: 10\n",
    "               \n",
    "               }\n",
    "\n",
    "model_yaml = model.to_yaml()\n",
    "with open(\"model_v8v6_layer_cnn.yaml\", \"w\") as yaml_file:\n",
    "    yaml_file.write(model_yaml)\n",
    "# checkpoint\n",
    "filepath=\"weights.bestv8v6.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "early_stopping = EarlyStopping(monitor='val_acc', patience=40)\n",
    "callbacks_list = [checkpoint, early_stopping]\n",
    "\n",
    "# Fit the model\n",
    "history = model.fit(X_train, y_1Hot_train, epochs=3000, validation_split=0.1 , class_weight=class_weight,callbacks=callbacks_list, shuffle=True, batch_size=5)\n",
    "\n",
    "\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"weights_v8v6_layer_cnn.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load weights into new model\n",
    "model.load_weights(\"C:\\jupyter\\weights.bestv8v6.hdf5\")\n",
    "print(\"Loaded model from disk\")\n",
    " \n",
    "# evaluate loaded model on test data\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "score = model.evaluate(X_test, y_1Hot_test, verbose=0, batch_size=5)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], score[1]*100))\n",
    "\n",
    "y_true, y_pred = y_1Hot_test.astype('int'), model.predict(X_test, batch_size=5)\n",
    "y_pred = y_pred.round().astype('int')\n",
    "\n",
    "# from categorial to lable indexing\n",
    "y_pred = y_pred.argmax(1)\n",
    "y_true = y_true.argmax(1)\n",
    "\n",
    "print(classification_report(y_true, y_pred))\n",
    "plot_confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n",
      "acc: 87.35%\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.95      0.91       262\n",
      "          1       0.92      0.89      0.91        38\n",
      "          2       0.87      0.71      0.78       116\n",
      "          3       0.55      0.55      0.55        11\n",
      "\n",
      "avg / total       0.87      0.87      0.87       427\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1wAAANqCAYAAACZxkp0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzs3XmYXGWd9//PTUJQTDCiKJAAskg2ZJGERRAQF7YoDgOy\nOCKDgDIiMs448PwYx2XUB9FHUNFxnNFRcQT3QdbIjsgaNpVNkUUSiAQQWUM6nfP7oyqZGLNUsO+u\n6ub1uq5c3XXqVJ1vNfTVeeecurs0TRMAAAAG3mrdHgAAAGC4ElwAAACVCC4AAIBKBBcAAEAlggsA\nAKASwQUAAFCJ4AIY5kopO5ZSvldKeaCUMr+U8kgp5cJSyqGllBEVj/uWUsovSynzSilNKWXsAD73\nbu3n3G2gnrNXlFJeWUr5aCllk1V8TFNKOaziaAA8B4ILYBgrpRyX5OdJ1k5yfJI3Jjk8ya+TfCXJ\n9ErHHZnkv5PMTvLmJDsmeWIAD3Fj+zlvHMDn7BWvTPKRJB0HV5IH0/p6nFtjIACeu5HdHgCAOkop\nuyT5XJLTmqY5dqm7zyql/L8koysdflySMUm+1zTNFQP95E3TPJ7kmoF+3qGmlFKSrN40zbPx9QDo\nSc5wAQxfxyd5NMk/LevOpmnubprmF4tul1K2K6VcVEp5spTyVCnl4lLKdks+ppTyjVLKrFLKNqWU\nn5VSni6l/KaU8t4l9vloknvbN7/WvtTtsvZ995ZSvrH0LO19PrrE7c1LKT8upTzUviTxd6WU77fP\nnC3zksLS8vellDvbl04+WEo5rZSy1jKO9YlSyrGllHtKKU+UUi4vpUxZ2Rd0idc/tZRyVSnlmfbx\n9mnf/8H2a3y8lHJWKWWdpR5/TCnl6lLKo6WUx0op1yx67KLXleTS9s0L27Mufp3t5/52KeXwUsod\nSeYn2WfpSwpLKeu2v3Y/Xur4R7b3q3JmE4A/J7gAhqH2e7Nen+SnTdPM62D/LZNcnuQlSQ5LcmiS\ntZJcXkrZaqnd10rynSTfTrJvkuuT/Fsp5fXt+/8zyQHtzz+R1qVuf7eKL+HctM6SHZ1kjyQnJHk2\nK/659cm0zuhdmOQtSU5uv5ZzSylLP+5vkuyT5ANJ/jbJhmmd9evkyo+1knwrrdf5V0keSvLD9hnD\n1yd5X5Lj2p9/aanHbpzkG0nenuTAJDOTnFNK2bN9/43txyfJsWl97Za+dPL1ST6Y5GNJ9kzyiyyl\naZo57df1tkUxXEqZlOTUJF9smuacDl4nAAPAJYUAw9PLkrwwyX0d7v8vaQXNG5qmeSxJSikXpnWm\n6iNJ9lti3zFJ/q5pmkvb+12RVhQdnOTSpmlmlVJubu/726ZpVulSt1LKy5JslmTfpml+ssRd31nB\nY9ZO8g9Jvtk0zTHtzTNKKXOTnJ7We9WWfK6+JNObpulrPz5Jvp9kuyRXrWTEMUneu+hSyVLKA0lu\naR9jctM0/e3tWyR5fyllxKJtTdP8wxIzr5bk4iSbpxWWFzRN83gp5bb2Lrcv52v3kiTbtqNq0XO9\ncumdmqY5t5TyhSSfK6Vcl+S/ktyV5EMreX0ADCBnuABIkl2SnLMotpLF75P6SZJdl9r36UWx1d7v\n2bQW4dhwgGZ5JMndSU5qXwL3qg4es0OSUWmddVvSmUkW5M9fw4WLYqvtl+2PnbyGp5Z6X9od7Y8X\nLQqrJbaPTLLeog2llG1LKeeUUn7fnqsvyZuSTOjguItcs2RsrcQ/pfXf5qokr0pycPu/FwCDRHAB\nDE+PJHkmyUYd7r92WivdLW1OWmdUlvSHZez3bJIXdDzdCjRN06QVITOT/N8kvy6l3F1KOXoFD1u7\n/fFPXkPTNAvS+lqsvdT+jy51e1GEdPIaHlvyRtM089ufLv11WbT9BUlSStkgrTNaayd5f5LXJpmW\n5IIOj7vIsv47LVM7rr6bZI20Li+9bSUPAWCACS6AYagdGpcleVMpZY0OHvJoknWXsX3dLDuwnqt5\naZ2JWqyU8tKld2ov6HFoknWSbJPkkiRfLqXstZznXRRQf/Ia2u/Jemn+PLC6Yc8kL07y9qZpvtc0\nzTVN08xMsuYqPk/T6Y7thUA+nFa87ltK2XcVjwXAX0hwAQxfJ6UVGycv685SysbtxTKS1oIZe5dS\nxixx/5i0Fp+4bABnui/JFktt22dZOyats11N09yc1iIRWcZjF7kmrTNKBy21/cC0Luu7bJUnHXiL\nwmrxpYyllM2T7LTUfovOtr3wLzlYKeUFSc5I69LGnZL8KK1VI9f/S54XgFVj0QyAYappmitKKR9M\na9GEyWmtjve7tC4RfEOSI5IcktYqd/+a1qIPF5dSPp3WWZTj04qEjw/gWGcm+Xop5ZQk5yTZKq2V\nBBdrR+Dn07oU7q4kI9r7LEjrTNefaZrm0fYqgf+nlPJUkvOSTEprlcQr0xu/EPiitF7Dt9qzrpfW\nSoO/y5/+A+iv2/sdXkp5NK0Au7NpmlX9xdGfSbJpktc0TTO/lHJkWot7fKuU8qb2pZsAVOYMF8Aw\n1jTNqUl2Tut9R59NK1i+kVaMvCfJ2e39fpFktySPJ/lmWiv7PZlk16ZpbhnAkb6Z/1318Oy0Vjf8\nq6X2mZNWhHwwrUU7zkiyflqrCt6wguc+sf2YvdKKuRPSWr59n6ZpFg7ga3hOmqa5Nck70npf3U/S\nWtDihCRXLLXfI0mOSStGL09r2f1tV+VY7d+zdUySDzRNc2f7eR9Nazn812c5v5sNgIFX/AMXAABA\nHc5wAQAAVCK4AAAAKhFcAAAAlQguAACASnp6Wfgy8oVNGTVm5TvC89w2kzbs9ggwJCy0ThR0pJRu\nTwC973f33ZuHH354pd8tvR1co8ZkjQlv7/YY0PN+fu1p3R4BhoR5ff3dHgGGhNVHuAgKVuZ1O07r\naD/fTQAAAJUILgAAgEoEFwAAQCWCCwAAoBLBBQAAUIngAgAAqERwAQAAVCK4AAAAKhFcAAAAlQgu\nAACASgQXAABAJYILAACgEsEFAABQieACAACoRHABAABUIrgAAAAqEVwAAACVCC4AAIBKBBcAAEAl\nggsAAKASwQUAAFCJ4AIAAKhEcAEAAFQiuAAAACoRXAAAAJUILgAAgEoEFwAAQCWCCwAAoBLBBQAA\nUIngAgAAqERwAQAAVCK4AAAAKhFcAAAAlQguAACASgQXAABAJYILAACgEsEFAABQieACAACoRHAB\nAABUIrgAAAAqEVwAAACVCC4AAIBKBBcAAEAlggsAAKASwQUAAFCJ4AIAAKhEcAEAAFQiuAAAACoR\nXAAAAJUILgAAgEoEFwAAQCWCCwAAoBLBBQAAUIngAgAAqERwAQAAVCK4AAAAKhFcAAAAlQguAACA\nSgQXAABAJYILAACgEsEFAABQieACAACoRHABAABUIrgAAAAqEVwAAACVCC4AAIBKBBcAAEAlggsA\nAKASwQUAAFCJ4AIAAKhEcAEAAFQiuAAAACoRXAAAAJUILgAAgEoEFwAAQCWCCwAAoBLBBQAAUIng\nAgAAqERwAQAAVCK4AAAAKhFcAAAAlQguAACASgQXAABAJYILAACgEsEFAABQieACAACoRHABAABU\nIrgAAAAqEVwAAACVCC4AAIBKBBcAAEAlggsAAKASwQUAAFCJ4GKx8a8Ymwu+emxu/OGJueEHJ+Z9\nB++WJDnxPXvntzM+kWvOPCHXnHlC9th58uLH/OPhb86vzvpIbvnxh/PGHSd1aXLoHT+dcUG2nDIh\nUyZuls+cfFK3x4Ge9ZUvfSE7Tt0qO267Zf7ttM93exzoSfPmzcuuO22fHaZunalbb5FPfPwj3R6J\n52BktwegdyzoX5gTPvej3HzHrIxec41c9Z3jc/G1dyRJvvjtS3Pq6Rf/yf4TN1k3B+zxmrxm/09m\nvXVenPO+ckxe/baPZ+HCphvjQ9f19/fnuGPfl3PPvzDjxo/PzjtMy/Tpb82kyZNX/mB4Hrnt1l/l\nm//1tVx8xdUZNWpU9t937+yx1z7ZZNPNuj0a9JQ11lgj5864OKNHj05fX1/e9PrX5c177JXttt+h\n26OxCpzhYrE5Dz+em++YlSR58ulnc8c9c7L+OmOXu//03bbM92fcmPl9C3LfA4/kt/c/nGlbvHKQ\npoXec/1112XTTTfLxptsklGjRuWAAw/KOWef1e2xoOf8+s47MnXqdllzzTUzcuTI7LTzLjn7rB93\neyzoOaWUjB49OknS19eXvr6+lFK6PBWrSnCxTBuut3a2njA+1//q3iTJ0Qfvmuu++3/ylY+8I2PH\nvDBJMm6dF2fWnD8sfszsh/6Q9V/+4m6MCz3hgQdmZ/z4DRbfHjdufGbPnt3FiaA3TZo8JVdfdWUe\nfeSRPP3007lwxvmZPWtWt8eCntTf358dp22Tjce/Iru/4Y2Ztt323R6JVTSowVVK2bOUcmcp5a5S\nygmDeWw696IXjsoZnz0iH/rsD/PEU/PyH9//WSZN/0i2P+ikzHn48Zz0wf26PSIAQ9iEiZPygQ9+\nKPu9Za/sv+/e2WLLrTNixIhujwU9acSIEbn6+pty5933Z+bM63Prrb/q9kisokELrlLKiCRfSrJX\nkslJDi6leGNDjxk5crWc8dkj893zZ+asS25Jkjz06BNZuLBJ0zT5+o9+nqlbbJQkmT33jxm/7ksW\nP3bcy1+SBx76Y1fmhl6w/vrjMmvW/Ytvz549K+PGjeviRNC73nnY4bnsquty3oWXZezYsdl0s1d1\neyToaWPHjs0uu+6Wi2Zc0O1RWEWDeYZruyR3NU1zd9M085OcmWTfQTw+HfjKR96RO++Zky98+5LF\n29Z92VqLP993961y228fTJKce9kvcsAer8mo1Udmo/Vfms02XGfxJYjwfDR12rTcdddvcu8992T+\n/Pn5/nfPzD7T39rtsaAnzX3ooSTJ/ff/Luf85H9ywIEHd3ki6D1z587NY489liR55plncsnFF2Xz\nCRO7PBWrajBXKRyX5P4lbs9K8mcXoZZSjkpyVJJk9dGDMhgtr916k7xj+vb55a9n55ozW1d8fuS0\nn+Tte0zNlhPGp2ma3Pfgo3n/J85Iktx+95z88Kc35aYfnpgF/Qtz3Enfs0Ihz2sjR47MKZ8/LW/Z\nZ4/09/fnXYcdnslTpnR7LOhJhx5yQP7w6KMZufrq+cwpX8iLxy5/kSZ4vvr9nAdz1LsPS39/fxYu\nXJj99j8ge+0zvdtjsYpK0wzOX5BLKfsn2bNpmiPat9+ZZPumaY5Z3mNWW/PlzRoT3j4o88FQ9ofr\nT+v2CDAkzOvr7/YIMCSsPsK6arAyr9txWm68YeZKl40czO+m2Uk2WOL2+PY2AACAYWkwg+v6JK8q\npWxcShmV5KAkPxnE4wMAAAyqQXsPV9M0C0opxySZkWREkq83TXPrYB0fAABgsA3mohlpmua8JOcN\n5jEBAAC6xTsiAQAAKhFcAAAAlQguAACASgQXAABAJYILAACgEsEFAABQieACAACoRHABAABUIrgA\nAAAqEVwAAACVCC4AAIBKBBcAAEAlggsAAKASwQUAAFCJ4AIAAKhEcAEAAFQiuAAAACoRXAAAAJUI\nLgAAgEoEFwAAQCWCCwAAoBLBBQAAUIngAgAAqERwAQAAVCK4AAAAKhFcAAAAlQguAACASgQXAABA\nJYILAACgEsEFAABQieACAACoRHABAABUIrgAAAAqEVwAAACVCC4AAIBKBBcAAEAlggsAAKASwQUA\nAFCJ4AIAAKhEcAEAAFQiuAAAACoRXAAAAJUILgAAgEoEFwAAQCWCCwAAoBLBBQAAUIngAgAAqERw\nAQAAVCK4AAAAKhFcAAAAlQguAACASgQXAABAJYILAACgEsEFAABQieACAACoRHABAABUIrgAAAAq\nEVwAAACVCC4AAIBKBBcAAEAlggsAAKASwQUAAFCJ4AIAAKhEcAEAAFQiuAAAACoRXAAAAJUILgAA\ngEoEFwAAQCWCCwAAoBLBBQAAUIngAgAAqERwAQAAVCK4AAAAKhFcAAAAlQguAACASgQXAABAJYIL\nAACgEsEFAABQieACAACoRHABAABUIrgAAAAqEVwAAACVCC4AAIBKBBcAAEAlggsAAKASwQUAAFCJ\n4AIAAKhEcAEAAFQiuAAAACoRXAAAAJUILgAAgEoEFwAAQCWCCwAAoBLBBQAAUMnIbg+wIltP2jBX\nXv3Fbo8BPW/2o890ewQYEtYb+4JujwBDwmqrlW6PAD2v0+8SZ7gAAAAqEVwAAACVCC4AAIBKBBcA\nAEAlggsAAKASwQUAAFCJ4AIAAKhEcAEAAFQiuAAAACoRXAAAAJUILgAAgEoEFwAAQCWCCwAAoBLB\nBQAAUIngAgAAqERwAQAAVCK4AAAAKhFcAAAAlQguAACASgQXAABAJYILAACgEsEFAABQieACAACo\nRHABAABUIrgAAAAqEVwAAACVCC4AAIBKBBcAAEAlggsAAKASwQUAAFCJ4AIAAKhEcAEAAFQiuAAA\nACoRXAAAAJUILgAAgEoEFwAAQCWCCwAAoBLBBQAAUIngAgAAqERwAQAAVCK4AAAAKhFcAAAAlQgu\nAACASgQXAABAJYILAACgEsEFAABQieACAACoRHABAABUIrgAAAAqEVwAAACVCC4AAIBKBBcAAEAl\nggsAAKASwQUAAFCJ4AIAAKhEcAEAAFQiuAAAACoRXAAAAJUILgAAgEoEFwAAQCWCCwAAoBLBBQAA\nUIngAgAAqERwAQAAVCK4AAAAKhFcAAAAlQguAACASgQXAABAJYILAACgEsEFAABQieACAACoRHAB\nAABUIrgAAAAqEVwAAACVCC4AAIBKBBcAAEAlggsAAKASwQUAAFCJ4AIAAKhEcAEAAFQiuAAAACoR\nXAAAAJUILgAAgEoEFwAAQCWCCwAAoBLBBQAAUIngAgAAqERwAQAAVCK4AAAAKhFcAAAAlQguAACA\nSgQXAABAJYILAACgEsEFAABQieCiI7Puvz97vXn3bLvVlEzdeot86Yuf7/ZI0BOenTcv++3xukx/\n/fbZc5dtc+rJ//on9//nv30+m71izTz6yMNdmhB6j58p0LmfzrggW06ZkCkTN8tnTj6p2+PwHIzs\n9gAMDSNGjsynPv3ZbLPNa/LEE09k5x2mZvc3vimTJk3u9mjQVaPWWCOn/+j8vOhFo9PX15eD3vKG\n7Lr7Htlm6nZ5YPasXHnZxVl//AbdHhN6ip8p0Jn+/v4cd+z7cu75F2bc+PHZeYdpmT79rZk02ffK\nUOIMFx1Zb731ss02r0mSjBkzJhMmTsoDs2d3eSrovlJKXvSi0UmSBX196VvQl1Ja933yX/4px//L\nJ1IWbQCS+JkCnbr+uuuy6aabZeNNNsmoUaNywIEH5Zyzz+r2WKwiwcUqu+/ee3PLLTdl2nbbd3sU\n6An9/f15y+7bZ/spG2XnXd+QrbfdLheef3bWXXf9TJqyZbfHg57mZwos3wMPzM74Ja6SGDdufGb7\nx4khZ9CCq5Ty9VLKQ6WUXw3WMRl4Tz75ZA45aP+c/NlTstZaa3V7HOgJI0aMyNmXXJsrb/5Nbrlx\nZu649Zf5yuc/k+OO/3C3R4Oe5mcK8HwwmGe4vpFkz0E8HgOsr68vhxy4fw486JDs+7b9uj0O9Jy1\nXjw2O+y8Sy6acU7u/919mb779tl16sTMeWB29n3TazP3oTndHhF6hp8psHLrrz8us2bdv/j27Nmz\nMm7cuC5OxHMxaMHVNM0VSR4drOMxsJqmydHvOSITJk7Mscd9sNvjQM945OG5efyPjyVJ5j3zTH5+\n+SWZvMVWue62+3L5zDty+cw7su7643LWhVdlnZev2+VpoTf4mQKdmTptWu666ze59557Mn/+/Hz/\nu2dmn+lv7fZYrCKrFNKRq6/6ec7479MzZYtXZ4dp2yRJPvrxT2bPvfbu8mTQXXN/PycfOvbILOxf\nmIULF2bvfffL7m/2fQEr4mcKdGbkyJE55fOn5S377JH+/v6867DDM3nKlG6PxSoqTdMM3sFKeWWS\nc5qm2WIF+xyV5Kgk2WDDDbe94zf3DspsMJQ9+Ni8bo8AQ8J6Y1/Q7RFgSFhtNaurwsrstP3U3HDD\nzJV+s/TcKoVN03y1aZqpTdNMfdnL1un2OAAAAM9ZzwUXAADAcDGYy8KfkeTqJBNKKbNKKe8erGMD\nAAB0w6AtmtE0zcGDdSwAAIBe4JJCAACASgQXAABAJYILAACgEsEFAABQieACAACoRHABAABUIrgA\nAAAqEVwAAACVCC4AAIBKBBcAAEAlggsAAKASwQUAAFCJ4AIAAKhEcAEAAFQiuAAAACoRXAAAAJUI\nLgAAgEoEFwAAQCWCCwAAoBLBBQAAUIngAgAAqERwAQAAVCK4AAAAKhFcAAAAlQguAACASgQXAABA\nJYILAACgEsEFAABQieACAACoRHABAABUIrgAAAAqEVwAAACVCC4AAIBKBBcAAEAlggsAAKASwQUA\nAFCJ4AIAAKhEcAEAAFQiuAAAACoRXAAAAJUILgAAgEoEFwAAQCWCCwAAoBLBBQAAUIngAgAAqERw\nAQAAVCK4AAAAKhFcAAAAlQguAACASgQXAABAJYILAACgEsEFAABQieACAACoRHABAABUIrgAAAAq\nEVwAAACVCC4AAIBKBBcAAEAlggsAAKASwQUAAFCJ4AIAAKhEcAEAAFQiuAAAACoZubw7Sil7d/ok\nTdOcNzDjAAAADB/LDa4k53T4HE2SEQMwCwAAwLCyouB64aBNAQAAMAwtN7iapnl2MAcBAAAYbjpe\nNKOUsnsp5QellJtKKePb2w4rpexabzwAAIChq6PgKqUckOTsJHOTTEwyqn3XmklOqDMaAADA0Nbp\nGa4Tk7y3aZqjkyxYYvtVSbYZ8KkAAACGgU6Da/MkVyxj++NJxg7cOAAAAMNHp8E1J8lmy9i+U5K7\nB24cAACA4aPT4PpaklNLKdum9Xu3XlFKOTDJZ5J8tdZwAAAAQ9mKfg/Xkj6VZO203rO1epKfp/Ve\nrs83TXNqpdkAAACGtI6Cq2maJsk/lFI+nuTVaZ0Z+2XTNH+oORwAAMBQ1ukZrkWeSuv9XEnyxADP\nAgAAMKx0+nu4Vi+lnJTksSR3tv88Vkr5dCll1IofDQAA8PzU6Rmu05K8NckHklzd3rZjkn9Na1n4\n9wz8aAAAAENbp8F1cJK3N01zwRLbbiulPJDkzAguAACAP9PpsvDPJLlvGdvvTTJ/wKYBAAAYRjoN\nrn9L8v8t+X6tUsrqSU5o3wcAAMBSlntJYSnle0tt2jPJm0spN7Vvb53khUlmVJoNAABgSFvRe7j6\nl7p97lK3Lx3gWQAAAIaV5QZX0zQHD+YgAAAAw02n7+ECAABgFXW6LHxKKQentTz8hkn+5JcdN00z\neYDnAgAAGPI6OsNVSjkuyVeS/DbJxCSXJLk/yfpJflBtOgAAgCGs00sKj05yVNM0f5+kL8nnmqbZ\nI8kXkqxTazgAAIChrNPg2iDJNe3Pn0kypv356UnePtBDAQAADAedBtfvk6zd/vx3SbZrf75RkjLQ\nQwEAAAwHnQbXpUmmtz//ZpJTSynnJ/lekrNqDAYAADDUdbpK4XsX7ds0zRdLKY8n2SnJxUm+WGk2\nAACAIa2j4GqaZn6S+Uvc/mZaZ7oAAABYjuUGVyml49+t1TTNbQMzDgAAwPCxojNcv0rSLOe+0r5v\n0ccRAzwXAADAkLei4Jo0aFMsx4L+JnOfeLbbY0DPW3fsC7o9AgwJF9w+p9sjwJCw56R1uz0C9Lzl\nnZla2nKDq2maOwdoFgAAgOelTpeFBwAAYBUJLgAAgEoEFwAAQCWCCwAAoJJVCq5SyuhSylallNVr\nDQQAADBcdBRcpZQXlVK+leTxJDck2aC9/bRSyokV5wMAABiyOj3D9X+TTEjy2iTzltj+0yQHDPRQ\nAAAAw8GKfvHxkvZN8vamaa4tpSz5O75uS7LJwI8FAAAw9HV6hmudJA8tY/uLBnAWAACAYaXT4Loh\nyd5L3F50luvwJFcP6EQAAADDRKeXFJ6Y5LxSysT2Y95XSpmSZLcku1aaDQAAYEjr6AxX0zRXpBVW\nL08yO8l+SZ5KslPTNNfVGw8AAGDo6vQMV5qmuSHJgRVnAQAAGFY6Cq5Syporur9pmqcHZhwAAIDh\no9MzXE/mfxfKWJYRAzALAADAsNJpcO211O3Vk2yT5IgkHx7QiQAAAIaJjoKraZoZy9h8Tinl10n+\nJsm3BnQqAACAYaDT38O1PDOT7D4QgwAAAAw3zzm4SimjkrwvrWXiAQAAWEqnqxTOzZ8umlGSjE0y\nP8mhFeYCAAAY8jpdNOOfl7q9MMncJFc1TfPQwI4EAAAwPKw0uEopI5P0JTmvaZo59UcCAAAYHlb6\nHq6maRYkOS3JGvXHAQAAGD46XTTjuiRb1RwEAABguOn0PVynJfl/pZT1k9yQ5Kkl72ya5raBHgwA\nAGCo6zS4vtf++OX2x0UrFpb25yMGcigAAIDhoNPgmlR1CgAAgGFohcFVSvl6kg80TXPnIM0DAAAw\nbKxs0Yx3JXnhYAwCAAAw3KwsuMqgTAEAADAMdbIsfLPyXQAAAFhaJ4tmzCllxSe6mqaxSiEAAMBS\nOgmuo5I8VnsQAACA4aaT4Dq7aZqHqk8CAAAwzKzsPVzevwUAAPAcWaUQAACgkhVeUtg0TSerGAIA\nALAMggoAAKASwQUAAFCJ4AIAAKhEcAEAAFQiuAAAACoRXAAAAJUILgAAgEoEFwAAQCWCCwAAoBLB\nBQAAUIngAgAAqERwAQAAVCK4AAAAKhFcAAAAlQguAACASgQXAABAJYILAACgEsEFAABQieACAACo\nRHABAABUIrgAAAAqEVwAAACVCC4AAIBKBBcAAEAlggsAAKASwQUAAFCJ4AIAAKhEcAEAAFQiuAAA\nACoRXAAAAJUILgAAgEoEFwAAQCWCCwAAoBLBBQAAUIngAgAAqERwAQAAVCK4AAAAKhFcAAAAlQgu\nAACASgQXAABAJYILAACgEsEFAABQieACAACoRHABAABUIrgAAAAqEVwAAACVCC4AAIBKBBcAAEAl\nggsAAKCuQB0qAAAX2UlEQVQSwQUAAFCJ4AIAAKhEcAEAAFQiuAAAACoRXAAAAJUILgAAgEoEFwAA\nQCUjuz0AvemB2ffng393RB6e+1BKKTn40MNz+HuOyW2/+kVO/Mf35+mnnsr4DTbKqf/+XxkzZq1u\njws9Yd68ednjDbvm2WefzYIFC/K2/f46//wvH+v2WNAzzj79q7nox99JKSUbvmpijvnYKTnjSydn\n5hUXZuTqo7Lu+I1yzMdOyYvWenG3R4WeMOv++3Pku9+Vh37/+5RS8rfvPjLve/8Huj0Wq8gZLpZp\n5IiR+eePn5SLrropP77g8pz+tX/Pb+68PSccd3SO//AnMuNnM7PHPm/NV087pdujQs9YY401cu6M\ni3PNzJtz9fU35aKfzsh1117T7bGgJzzy+wdz3hlfy8nfOT+n/vDSLOxfmCsvOCtb7bBLTv3BpTnl\n+xdn/Y02yY++/sVujwo9Y8TIkfnUpz+bG265NZf+7Op89Stfzu2339btsVhFgotlevm662WLrbZJ\nkoweMyabbj4xcx58IPf89q5s/9qdkyQ777Z7zj/7f7o5JvSUUkpGjx6dJOnr60tfX19KKV2eCnpH\nf/+CzH92XvoXLMj8ec9k7XVeka1fu1tGjGxdcLP5ltvmkd8/2OUpoXest9562Wab1yRJxowZkwkT\nJ+WB2bO7PBWrSnCxUvf/7r7c9subs/W20/KqiZPy0/PPTpKcd9aP8uDsWV2eDnpLf39/dpy2TTYe\n/4rs/oY3Ztp223d7JOgJL33FennroUfnvXtOyxFv2jprjh6TrV+725/sc/H/nJFtdt69OwNCj7vv\n3ntzyy03+bkyBA1acJVSNiilXFpKua2UcmspxQWoQ8BTTz6Zow87OP/yyc9kzJi1cvIX/j3f/vpX\nM3331+bJJ5/M6qNGdXtE6CkjRozI1dfflDvvvj8zZ16fW2/9VbdHgp7w5OOP5frLZuTL516b//jp\nTZn3zNO5/NwfLr7/B//x+YwYMTK77L1fF6eE3vTkk0/mkIP2z8mfPSVrreW980PNYJ7hWpDkH5qm\nmZxkhyTvK6VMHsTjs4r6+vry3r89OG/b/8DsOf1tSZLNXjUhp//gnJxzyVV5635vz0av3LjLU0Jv\nGjt2bHbZdbdcNOOCbo8CPeEX1/wsLx+3QV689kszcvXVs8Mb9s6dN89Mklxy1ndzw88uynGfOs1l\nuLCUvr6+HHLg/jnwoEOy79v8g8RQNGjB1TTNg03T3Nj+/IkktycZN1jHZ9U0TZPjP/DebLb5hBzx\nd/97MvLhuQ8lSRYuXJjTPndS3nHYkd0aEXrO3Llz89hjjyVJnnnmmVxy8UXZfMLELk8FveFl643L\nr39xY5595uk0TZNfXntlxm+yWW76+aU565tfzgmnfiNrvHDNbo8JPaVpmhz9niMyYeLEHHvcB7s9\nDs9RV5aFL6W8Msk2Sa5dxn1HJTkqScaN32BQ5+J/zbz2qvzoe9/JxMlbZK/dWtcK/9OJH8s9d9+V\n07/270mSPabvmwMOObSbY0JP+f2cB3PUuw9Lf39/Fi5cmP32PyB77TO922NBT9j81a/Jjm/cJ/94\n8B4ZMWJkNp64Rd7013+T4/769emb/2w+/t4DW/ttuW3e88+f7vK00BuuvurnOeO/T8+ULV6dHaa1\nFjP76Mc/mT332rvLk7EqStM0g3vAUkYnuTzJJ5um+dGK9t1y622bsy/++eAMBkPYy8as0e0RYEiY\ncfucbo8AQ8Kek9bt9gjQ83becVpuvGHmSq+DHtRVCkspqyf5YZL/XllsAQAADHWDuUphSfK1JLc3\nTfO5wTouAABAtwzmGa6dkrwzye6llJvbf1yACgAADFuDtmhG0zRXJrHWKwAA8LwxqO/hAgAAeD4R\nXAAAAJUILgAAgEoEFwAAQCWCCwAAoBLBBQAAUIngAgAAqERwAQAAVCK4AAAAKhFcAAAAlQguAACA\nSgQXAABAJYILAACgEsEFAABQieACAACoRHABAABUIrgAAAAqEVwAAACVCC4AAIBKBBcAAEAlggsA\nAKASwQUAAFCJ4AIAAKhEcAEAAFQiuAAAACoRXAAAAJUILgAAgEoEFwAAQCWCCwAAoBLBBQAAUIng\nAgAAqERwAQAAVCK4AAAAKhFcAAAAlQguAACASgQXAABAJYILAACgEsEFAABQieACAACoRHABAABU\nIrgAAAAqEVwAAACVCC4AAIBKBBcAAEAlggsAAKASwQUAAFCJ4AIAAKhEcAEAAFQiuAAAACoRXAAA\nAJUILgAAgEoEFwAAQCWCCwAAoBLBBQAAUIngAgAAqERwAQAAVCK4AAAAKhFcAAAAlQguAACASgQX\nAABAJYILAACgEsEFAABQieACAACoRHABAABUIrgAAAAqEVwAAACVCC4AAIBKBBcAAEAlggsAAKAS\nwQUAAFCJ4AIAAKhEcAEAAFQiuAAAACoRXAAAAJUILgAAgEoEFwAAQCWCCwAAoBLBBQAAUIngAgAA\nqERwAQAAVCK4AAAAKhFcAAAAlQguAACASgQXAABAJYILAACgEsEFAABQieACAACoRHABAABUIrgA\nAAAqEVwAAACVCC4AAIBKBBcAAEAlggsAAKASwQUAAFCJ4AIAAKhkZLcHWJGRI0peOnpUt8eAnjdi\ntdLtEWBI2Gvyut0eAYaEBf1Nt0eAYcMZLgAAgEoEFwAAQCWCCwAAoBLBBQAAUIngAgAAqERwAQAA\nVCK4AAAAKhFcAAAAlQguAACASgQXAABAJYILAACgEsEFAABQieACAACoRHABAABUIrgAAAAqEVwA\nAACVCC4AAIBKBBcAAEAlggsAAKASwQUAAFCJ4AIAAKhEcAEAAFQiuAAAACoRXAAAAJUILgAAgEoE\nFwAAQCWCCwAAoBLBBQAAUIngAgAAqERwAQAAVCK4AAAAKhFcAAAAlQguAACASgQXAABAJYILAACg\nEsEFAABQieACAACoRHABAABUIrgAAAAqEVwAAACVCC4AAIBKBBcAAEAlggsAAKASwQUAAFCJ4AIA\nAKhEcAEAAFQiuAAAACoRXAAAAJUILgAAgEoEFwAAQCWCCwAAoBLBBQAAUIngAgAAqERwAQAAVCK4\nAAAAKhFcAAAAlQguAACASgQXAABAJYILAACgEsEFAABQieACAACoRHABAABUIrgAAAAqEVwAAACV\nCC4AAIBKBBcAAEAlggsAAKASwQUAAFCJ4AIAAKhEcAEAAFQiuAAAACoRXAAAAJUILgAAgEoEFwAA\nQCWCCwAAoBLBBQAAUIngAgAAqERwAQAAVCK4AAAAKhFcAAAAlQguAACASgQXAABAJYILAACgEsEF\nAABQieACAACoRHABAABUIrgAAAAqEVwAAACVCC4AAIBKBBcAAEAlggsAAKASwQUAAFCJ4AIAAKhE\ncAEAAFQiuOhYf39/dtp+2+z/V2/p9ijQs34644JsOWVCpkzcLJ85+aRujwM96T1HHp6Nxr0iU7d+\ndbdHgZ732GOP5Z0HH5Btt5qcqVtPybXXXN3tkVhFgouOffm0L2TChIndHgN6Vn9/f4479n056+zz\nc9Mvbsv3zzwjt992W7fHgp7zzkMPy/+cc363x4Ah4fh/PC5vfPMeueGW23LVdTdlwsRJ3R6JVSS4\n6MjsWbMy4/zz8q6/fXe3R4Gedf1112XTTTfLxptsklGjRuWAAw/KOWef1e2xoOfs/LpdsvZL1u72\nGNDz/vjHP+aqK3+WQw9r/f1r1KhRGTt2bJenYlUJLjpy/If+Pv/6qZOy2mr+l4HleeCB2Rk/foPF\nt8eNG5/Zs2d3cSIAhrL77r0nL33ZOjn6qMOz8w7b5pijj8xTTz3V7bFYRYP2t+dSygtKKdeVUm4p\npdxaSvnYYB2bv8z5552TddZ5ebZ5zbbdHgUA4HljwYIFueXmG/PuI9+bK6+5IWuu+aJ87rOf7vZY\nrKLBPF3xbJLdm6bZKsnWSfYspewwiMfnObrmqqty3rlnZ8rmm+SwQw/JFZddmiMOe2e3x4Kes/76\n4zJr1v2Lb8+ePSvjxo3r4kQADGXjxo3PuHHjM2277ZMkb/urv84tN9/Y5alYVYMWXE3Lk+2bq7f/\nNIN1fJ67j33iU7nzt7/Lrb++O9/41neyy26vz39+4/RujwU9Z+q0abnrrt/k3nvuyfz58/P9756Z\nfaa/tdtjATBEvWLddTNu/Ab5za/vTJJcdtklmThxcpenYlUN6htySikjSik3J3koyYVN01y7jH2O\nKqXMLKXMfHju3MEcD+AvMnLk/9/e/Qd7WtV1AH9/lhUCZrJp1h8riJhgCwu5sLADWkozOGyBo6OU\nE2m4TlPRiFmpUDoj6aQDYobtpDbqYhlU2hTKOGqpqUmx/BTIXSmBXUERmqkMFwHl9MfzbF1u9+69\nFzj3+70zr9fMnd3v8+Ocz/c788y97+85z3lW592XbM2LTj8tG449Ki/7uZ/P0evXT7osmDpnv+Ks\nnPL85+bWW7+WI5759Fy67YOTLgmm1jv/4JL88pZX5uQTN+Tmr9yY337j70y6JJaoWlv+Qaaq+pEk\nf5Pk3NbaLfMdd/zGE9oXr9q+fIXBCrV6P4uZwGJM4ncerETf/4FrBRbygudtyvXXXVsLHTeRv9Ja\na/+Z5PNJNk+ifwAAgOWwnKsUPmkc2UpVHZjkhUl2Llf/AAAAy231Mva1NsmHq2q/DEHvr1prVy5j\n/wAAAMtq2QJXa+2mJMctV38AAACT5k57AACATgQuAACATgQuAACATgQuAACATgQuAACATgQuAACA\nTgQuAACATgQuAACATgQuAACATgQuAACATgQuAACATgQuAACATgQuAACATgQuAACATgQuAACATgQu\nAACATgQuAACATgQuAACATgQuAACATgQuAACATgQuAACATgQuAACATgQuAACATgQuAACATgQuAACA\nTgQuAACATgQuAACATgQuAACATgQuAACATgQuAACATgQuAACATgQuAACATgQuAACATgQuAACATgQu\nAACATgQuAACATgQuAACATgQuAACATgQuAACATgQuAACATgQuAACATgQuAACATgQuAACATgQuAACA\nTgQuAACATgQuAACATgQuAACATgQuAACATgQuAACATgQuAACATgQuAACATgQuAACATgQuAACATgQu\nAACATgQuAACATgQuAACATgQuAACATgQuAACATgQuAACATgQuAACATgQuAACATgQuAACATgQuAACA\nTgQuAACATgQuAACATgQuAACATgQuAACATgQuAACATgQuAACATgQuAACATgQuAACATgQuAACATgQu\nAACATgQuAACATgQuAACATgQuAACATgQuAACATgQuAACATgQuAACATgQuAACATgQuAACATgQuAACA\nTgQuAACATgQuAACATgQuAACATgQuAACATgQuAACATgQuAACATgQuAACATgQuAACATgQuAACATgQu\nAACATgQuAACATgQuAACATgQuAACATqq1Nuka5lVV9ybZNek6eIQ1Sf590kXACuBagYW5TmBxXCvT\n6RmttSctdNBUBy6mT1Vd21o7YdJ1wLRzrcDCXCewOK6Vlc2UQgAAgE4ELgAAgE4ELpbqTyZdAKwQ\nrhVYmOsEFse1soK5hwsAAKATI1wAAACdCFwAAACdCFwAAACdCFwAAACdrJ50AUy3qlqX5MVJDhk3\n3ZXk4621HZOrCoCVaPydckiSq1tr983Yvrm19qnJVQbTpao2JWmttWuq6ugkm5PsbK19csKl8SgY\n4WJeVXVekr9IUkm2jz+V5PKqOn+StcFKUVVbJl0DTIOqem2SK5Kcm+SWqnrxjN1vn0xVMH2q6i1J\n3pPkvVX1jiRbkxyc5PyqetNEi+NRsSw886qqW5Osb609NGv7/kn+pbV25GQqg5Wjqna31g6bdB0w\naVV1c5KTW2v3VdXhST6W5M9aa5dU1Q2tteMmWiBMifFa2ZDkgCR3Jzm0tfadqjoww+jwT0y0QJbM\nlEL25eEkT0uya9b2teM+IElV3TTfriRPWc5aYIqt2juNsLV2R1WdkuRjVfWMDNcKMPh+a+0HSfZU\n1ddba99Jktba/VXl768VSOBiX16X5LNV9a9JvjFuOyzJEUleM7GqYPo8JclpSf5j1vZKctXylwNT\n6dtVtaG1dmOSjCNdZyT5UJJjJ1saTJUHq+qg1tqeJBv3bqyqJ8YX3iuSKYXsU1WtSrIpj1w045rx\nmxcgSVV9MMm21to/zrHvstbaWRMoC6ZKVR2a4Zv7u+fY97zW2pcnUBZMnao6oLX2wBzb1yRZ21q7\neQJl8RgIXAAAAJ1YpRAAAKATgQsAAKATgQuAqVFVt1TVBTNe31FVr59AHSdUVRuXL5/vmH+oqq1L\naPOUsc01j7G2S6vqysfSBgDLR+ACYF7jH/dt/Hmoqm6rqour6uBlKuHEJH+8mAOr6lVVdV/negBg\nSSwLD8BC/j7JK5M8IclPJflAkoOS/PpcB1fVE2Y/MP3Raq3d+3i0AwCTYoQLgIU80Fq7u7X2jdba\nZUk+kuQlySOmyf1sVW2vqgczPJMsVfWiqrquqr5XVbdX1e9X1f57G62qJ1fVFVV1f1XtqqpXz+54\n9pTCqnpiVb23qr41trujql4+PkR3W5KDZ4zIXTCes39VXVhVd1bVnqq6pqpOm9XP5qraObb5pSTP\nXuqHVFWvGNv+76q6p6o+WlWHzHHoSVV149jXdVW1cVY7z62qL4y13jW+3x9eaj0ATAeBC4Cl+l6S\nA2ZtuzDJm5OsS3L1GGj+PMnWJOuTvDrJmUnePuOcSzM8SP3UDAHul5IcPl+nVVVJPpnkBUm2JDkq\nyW8keSDDA6Zfl2RPkrXjz8XjqdvGc85KckySDyf5RFU9Z2z36Un+NsnfJdmQ5I+SXLTYD2OG/ZO8\nJclzkpyRZE2Sy+c47uIk5yU5IcltSa6sqoPGWo5N8pkkHx/beelY04ceRT0ATAFTCgFYtKralOQX\nM0wznOmC1tpnZhz3piTvbK1tGzd9varOS/KRqnpDkiOT/EySn9z7wNuqOjtDAJnPqUlOTrK+tbZj\n3Hb7jD7/K0mb+WDdqnpWkl9Icnhrbfe4eWtVnZrkVzNMizwnye4kr23Dwyl3VtWzk7xtUR/KqLU2\nMxTdVlXnJNlRVYe21u6cse9trbVPj/VtSXJnhjD4gSRvSPKXrbV3zXgP5yS5oaqe3Fq7Zyk1ATB5\nAhcAC9k8LkaxOsN9XFckOXfWMdfOer0xyaYxZO21KsmBSZ6aYXTq4STb9+5sre2qqm/uo47jknxr\nRthajOOTVJKvDgNk/+uAJJ8b/39Ukn8ew9Ze/7SEPpIkVXV8hhGuDUl+dOw3SQ7LEKr+X9uttfuq\n6uYkR4+bNiY5oqpePrPp8d9nJRG4AFYYgQuAhXwxya8keSjJN+dZEOO7s16vSvJ7ST46x7EzF8Jo\nc+x/PK0a+zgxQ/0z3f94dTKu2vjp/N8CI/dkmFL4pQxTDRdrVYaRrnfPse+ux1gmABMgcAGwkD2t\ntX9b4jnXJ1k333lVtTNDuNiU4f6rVNVhSZ62jzZvSLK2qo6aZ5TrwST7zXFOJXlqa+3z87S7I8nL\nqqpmjHKdtI865rIuQ8D63dba7UlSVS+d59iTMk6dHIPaMUn+dNx3fYYpk0v9vAGYUhbNAKCHtyY5\nq6reWlXHVNW6qjqzqi5Kktba15J8Ksn7q+rkqtqQYRGNfY06fTbJ1Un+uqpOq6pnVtULq+ol4/47\nkvzQuG1NVR3UWrs1w+Idl479/1gNDzV+/YxA9L4Mi3X8YVX9eFWdmeTXlvh+d2dYvOM1Yx+nZ/57\nwN481rg+w2IYDya5bNx3YYapmO+rquOq6oiqOqOq3r/EegCYEgIXAI+7cVGI05P8dIb7tLYnOT9D\nMNnrVRkWvfhckk9kCB137KPNhzMstPHlDEvT70hyScYpe621qzKEp8szTFt843jqlgwrFV6UZGeS\nK5M8P8mu8bzdGVYD3JzkK0l+c6x1Ke/33iRnZ1ht8asZ7uX6rXkOPz/JuzKMZh2Z5IzW2nfHdm4a\nazs8yRfGet6R5NtLqQeA6VGPvEcYAACAx4sRLgAAgE4ELgAAgE4ELgAAgE4ELgAAgE4ELgAAgE4E\nLgAAgE4ELgAAgE4ELgAAgE7+B+zXaDhs1FW/AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x20dceda4710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load weights into new model\n",
    "model.load_weights(\"C:\\jupyter\\weights.bestv8v5.hdf5\")\n",
    "print(\"Loaded model from disk\")\n",
    " \n",
    "# evaluate loaded model on test data\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "score = model.evaluate(X_test, y_1Hot_test, verbose=0, batch_size=5)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], score[1]*100))\n",
    "\n",
    "y_true, y_pred = y_1Hot_test.astype('int'), model.predict(X_test, batch_size=5)\n",
    "y_pred = y_pred.round().astype('int')\n",
    "\n",
    "# from categorial to lable indexing\n",
    "y_pred = y_pred.argmax(1)\n",
    "y_true = y_true.argmax(1)\n",
    "\n",
    "print(classification_report(y_true, y_pred))\n",
    "plot_confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n",
      "acc: 85.48%\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.94      0.91       262\n",
      "          1       0.94      0.79      0.86        38\n",
      "          2       0.78      0.75      0.77       116\n",
      "          3       0.60      0.27      0.37        11\n",
      "\n",
      "avg / total       0.85      0.86      0.85       427\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1wAAANqCAYAAACZxkp0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nuAAAACYRuAAAACb5H+MySKTnhZWIAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x20db4bfd710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load weights into new model\n",
    "model.load_weights(\"C:\\jupyter\\weights.bestv8v4b.hdf5\")\n",
    "print(\"Loaded model from disk\")\n",
    " \n",
    "# evaluate loaded model on test data\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "score = model.evaluate(X_test, y_1Hot_test, verbose=0, batch_size=10)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], score[1]*100))\n",
    "\n",
    "y_true, y_pred = y_1Hot_test.astype('int'), model.predict(X_test, batch_size=10)\n",
    "y_pred = y_pred.round().astype('int')\n",
    "\n",
    "# from categorial to lable indexing\n",
    "y_pred = y_pred.argmax(1)\n",
    "y_true = y_true.argmax(1)\n",
    "\n",
    "print(classification_report(y_true, y_pred))\n",
    "plot_confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6480 samples, validate on 1621 samples\n",
      "Epoch 1/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 1.3819 - acc: 0.5857Epoch 00000: val_acc improved from -inf to 0.60457, saving model to weights.bestv8v3.hdf5\n",
      "6480/6480 [==============================] - 115s - loss: 1.3805 - acc: 0.5858 - val_loss: 1.4265 - val_acc: 0.6046\n",
      "Epoch 2/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 1.3837 - acc: 0.5899Epoch 00001: val_acc did not improve\n",
      "6480/6480 [==============================] - 66s - loss: 1.3823 - acc: 0.5901 - val_loss: 1.4299 - val_acc: 0.6046\n",
      "Epoch 3/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 1.0183 - acc: 0.5908Epoch 00002: val_acc improved from 0.60457 to 0.61690, saving model to weights.bestv8v3.hdf5\n",
      "6480/6480 [==============================] - 66s - loss: 1.0178 - acc: 0.5910 - val_loss: 0.9118 - val_acc: 0.6169\n",
      "Epoch 4/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.9613 - acc: 0.5947Epoch 00003: val_acc did not improve\n",
      "6480/6480 [==============================] - 66s - loss: 0.9612 - acc: 0.5948 - val_loss: 1.0784 - val_acc: 0.6107\n",
      "Epoch 5/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.8882 - acc: 0.6142Epoch 00004: val_acc improved from 0.61690 to 0.67983, saving model to weights.bestv8v3.hdf5\n",
      "6480/6480 [==============================] - 66s - loss: 0.8884 - acc: 0.6142 - val_loss: 0.8211 - val_acc: 0.6798\n",
      "Epoch 6/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.8813 - acc: 0.6491Epoch 00005: val_acc did not improve\n",
      "6480/6480 [==============================] - 66s - loss: 0.8819 - acc: 0.6489 - val_loss: 0.9892 - val_acc: 0.6299\n",
      "Epoch 7/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.8017 - acc: 0.6765Epoch 00006: val_acc did not improve\n",
      "6480/6480 [==============================] - 66s - loss: 0.8014 - acc: 0.6767 - val_loss: 0.8190 - val_acc: 0.6638\n",
      "Epoch 8/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.7490 - acc: 0.7027Epoch 00007: val_acc did not improve\n",
      "6480/6480 [==============================] - 66s - loss: 0.7488 - acc: 0.7026 - val_loss: 1.8187 - val_acc: 0.4460\n",
      "Epoch 9/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.7576 - acc: 0.7028Epoch 00008: val_acc improved from 0.67983 to 0.70512, saving model to weights.bestv8v3.hdf5\n",
      "6480/6480 [==============================] - 66s - loss: 0.7579 - acc: 0.7026 - val_loss: 0.8627 - val_acc: 0.7051\n",
      "Epoch 10/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.7124 - acc: 0.7256Epoch 00009: val_acc improved from 0.70512 to 0.73535, saving model to weights.bestv8v3.hdf5\n",
      "6480/6480 [==============================] - 66s - loss: 0.7127 - acc: 0.7253 - val_loss: 0.7204 - val_acc: 0.7353\n",
      "Epoch 11/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.6807 - acc: 0.7269Epoch 00010: val_acc did not improve\n",
      "6480/6480 [==============================] - 66s - loss: 0.6802 - acc: 0.7273 - val_loss: 1.0883 - val_acc: 0.5046\n",
      "Epoch 12/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.8259 - acc: 0.6532Epoch 00011: val_acc did not improve\n",
      "6480/6480 [==============================] - 66s - loss: 0.8258 - acc: 0.6534 - val_loss: 0.8172 - val_acc: 0.6317\n",
      "Epoch 13/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.7245 - acc: 0.7010Epoch 00012: val_acc did not improve\n",
      "6480/6480 [==============================] - 66s - loss: 0.7243 - acc: 0.7008 - val_loss: 0.6808 - val_acc: 0.7236\n",
      "Epoch 14/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.7471 - acc: 0.6926Epoch 00013: val_acc did not improve\n",
      "6480/6480 [==============================] - 66s - loss: 0.7471 - acc: 0.6924 - val_loss: 0.8234 - val_acc: 0.6447\n",
      "Epoch 15/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.6801 - acc: 0.7109Epoch 00014: val_acc improved from 0.73535 to 0.74769, saving model to weights.bestv8v3.hdf5\n",
      "6480/6480 [==============================] - 66s - loss: 0.6803 - acc: 0.7110 - val_loss: 0.6519 - val_acc: 0.7477\n",
      "Epoch 16/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.7474 - acc: 0.6816Epoch 00015: val_acc did not improve\n",
      "6480/6480 [==============================] - 66s - loss: 0.7480 - acc: 0.6813 - val_loss: 0.9469 - val_acc: 0.6033\n",
      "Epoch 17/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.8174 - acc: 0.6660Epoch 00016: val_acc did not improve\n",
      "6480/6480 [==============================] - 66s - loss: 0.8170 - acc: 0.6662 - val_loss: 0.7821 - val_acc: 0.6767\n",
      "Epoch 18/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.7235 - acc: 0.7093Epoch 00017: val_acc did not improve\n",
      "6480/6480 [==============================] - 66s - loss: 0.7238 - acc: 0.7091 - val_loss: 0.8556 - val_acc: 0.6737\n",
      "Epoch 19/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.7170 - acc: 0.7068Epoch 00018: val_acc did not improve\n",
      "6480/6480 [==============================] - 65s - loss: 0.7179 - acc: 0.7062 - val_loss: 1.1781 - val_acc: 0.6070\n",
      "Epoch 20/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.6876 - acc: 0.7087Epoch 00019: val_acc did not improve\n",
      "6480/6480 [==============================] - 65s - loss: 0.6903 - acc: 0.7085 - val_loss: 0.7946 - val_acc: 0.7138\n",
      "Epoch 21/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.6707 - acc: 0.7254Epoch 00020: val_acc did not improve\n",
      "6480/6480 [==============================] - 66s - loss: 0.6705 - acc: 0.7256 - val_loss: 0.7057 - val_acc: 0.7292\n",
      "Epoch 22/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.7141 - acc: 0.7014Epoch 00021: val_acc did not improve\n",
      "6480/6480 [==============================] - 66s - loss: 0.7133 - acc: 0.7019 - val_loss: 0.8339 - val_acc: 0.7051\n",
      "Epoch 23/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.6998 - acc: 0.7181Epoch 00022: val_acc did not improve\n",
      "6480/6480 [==============================] - 66s - loss: 0.7000 - acc: 0.7181 - val_loss: 0.6477 - val_acc: 0.7372\n",
      "Epoch 24/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.6582 - acc: 0.7351Epoch 00023: val_acc did not improve\n",
      "6480/6480 [==============================] - 66s - loss: 0.6581 - acc: 0.7352 - val_loss: 0.6544 - val_acc: 0.7187\n",
      "Epoch 25/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.6899 - acc: 0.7218Epoch 00024: val_acc improved from 0.74769 to 0.74830, saving model to weights.bestv8v3.hdf5\n",
      "6480/6480 [==============================] - 66s - loss: 0.6899 - acc: 0.7219 - val_loss: 0.6318 - val_acc: 0.7483\n",
      "Epoch 26/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.6115 - acc: 0.7466Epoch 00025: val_acc improved from 0.74830 to 0.74830, saving model to weights.bestv8v3.hdf5\n",
      "6480/6480 [==============================] - 66s - loss: 0.6114 - acc: 0.7466 - val_loss: 0.6398 - val_acc: 0.7483\n",
      "Epoch 27/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.6220 - acc: 0.7398Epoch 00026: val_acc improved from 0.74830 to 0.75324, saving model to weights.bestv8v3.hdf5\n",
      "6480/6480 [==============================] - 66s - loss: 0.6220 - acc: 0.7394 - val_loss: 0.6175 - val_acc: 0.7532\n",
      "Epoch 28/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.5877 - acc: 0.7562Epoch 00027: val_acc did not improve\n",
      "6480/6480 [==============================] - 66s - loss: 0.5880 - acc: 0.7560 - val_loss: 0.7365 - val_acc: 0.7316\n",
      "Epoch 29/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.5883 - acc: 0.7605Epoch 00028: val_acc improved from 0.75324 to 0.76126, saving model to weights.bestv8v3.hdf5\n",
      "6480/6480 [==============================] - 66s - loss: 0.5885 - acc: 0.7606 - val_loss: 0.6868 - val_acc: 0.7613\n",
      "Epoch 30/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.5830 - acc: 0.7579Epoch 00029: val_acc improved from 0.76126 to 0.76743, saving model to weights.bestv8v3.hdf5\n",
      "6480/6480 [==============================] - 66s - loss: 0.5832 - acc: 0.7577 - val_loss: 0.6328 - val_acc: 0.7674\n",
      "Epoch 31/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.5660 - acc: 0.7731Epoch 00030: val_acc did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6480/6480 [==============================] - 65s - loss: 0.5658 - acc: 0.7733 - val_loss: 0.6823 - val_acc: 0.7557\n",
      "Epoch 32/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.5687 - acc: 0.7666Epoch 00031: val_acc improved from 0.76743 to 0.76990, saving model to weights.bestv8v3.hdf5\n",
      "6480/6480 [==============================] - 66s - loss: 0.5692 - acc: 0.7662 - val_loss: 0.5967 - val_acc: 0.7699\n",
      "Epoch 33/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.5459 - acc: 0.7778Epoch 00032: val_acc improved from 0.76990 to 0.77421, saving model to weights.bestv8v3.hdf5\n",
      "6480/6480 [==============================] - 67s - loss: 0.5457 - acc: 0.7779 - val_loss: 0.5710 - val_acc: 0.7742\n",
      "Epoch 34/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.5461 - acc: 0.7865Epoch 00033: val_acc improved from 0.77421 to 0.78717, saving model to weights.bestv8v3.hdf5\n",
      "6480/6480 [==============================] - 68s - loss: 0.5457 - acc: 0.7867 - val_loss: 0.6127 - val_acc: 0.7872\n",
      "Epoch 35/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.6088 - acc: 0.7588Epoch 00034: val_acc did not improve\n",
      "6480/6480 [==============================] - 68s - loss: 0.6089 - acc: 0.7588 - val_loss: 0.7469 - val_acc: 0.6761\n",
      "Epoch 36/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.5594 - acc: 0.7687Epoch 00035: val_acc did not improve\n",
      "6480/6480 [==============================] - 68s - loss: 0.5597 - acc: 0.7687 - val_loss: 0.6198 - val_acc: 0.7816\n",
      "Epoch 37/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.5506 - acc: 0.7922Epoch 00036: val_acc did not improve\n",
      "6480/6480 [==============================] - 68s - loss: 0.5504 - acc: 0.7923 - val_loss: 0.7621 - val_acc: 0.7594\n",
      "Epoch 38/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.5327 - acc: 0.7975Epoch 00037: val_acc improved from 0.78717 to 0.80074, saving model to weights.bestv8v3.hdf5\n",
      "6480/6480 [==============================] - 69s - loss: 0.5321 - acc: 0.7977 - val_loss: 0.5959 - val_acc: 0.8007\n",
      "Epoch 39/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.5477 - acc: 0.7932Epoch 00038: val_acc improved from 0.80074 to 0.80259, saving model to weights.bestv8v3.hdf5\n",
      "6480/6480 [==============================] - 69s - loss: 0.5474 - acc: 0.7931 - val_loss: 0.5492 - val_acc: 0.8026\n",
      "Epoch 40/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.5313 - acc: 0.8051Epoch 00039: val_acc improved from 0.80259 to 0.80568, saving model to weights.bestv8v3.hdf5\n",
      "6480/6480 [==============================] - 68s - loss: 0.5304 - acc: 0.8054 - val_loss: 0.5886 - val_acc: 0.8057\n",
      "Epoch 41/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.5203 - acc: 0.8066Epoch 00040: val_acc improved from 0.80568 to 0.80753, saving model to weights.bestv8v3.hdf5\n",
      "6480/6480 [==============================] - 68s - loss: 0.5203 - acc: 0.8066 - val_loss: 0.5326 - val_acc: 0.8075\n",
      "Epoch 42/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.5346 - acc: 0.8034Epoch 00041: val_acc did not improve\n",
      "6480/6480 [==============================] - 67s - loss: 0.5344 - acc: 0.8035 - val_loss: 0.5720 - val_acc: 0.7946\n",
      "Epoch 43/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.5092 - acc: 0.8100Epoch 00042: val_acc did not improve\n",
      "6480/6480 [==============================] - 65s - loss: 0.5091 - acc: 0.8102 - val_loss: 0.7614 - val_acc: 0.7680\n",
      "Epoch 44/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.5088 - acc: 0.8058Epoch 00043: val_acc did not improve\n",
      "6480/6480 [==============================] - 65s - loss: 0.5081 - acc: 0.8062 - val_loss: 0.5655 - val_acc: 0.8063\n",
      "Epoch 45/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.4954 - acc: 0.8083Epoch 00044: val_acc did not improve\n",
      "6480/6480 [==============================] - 66s - loss: 0.4975 - acc: 0.8083 - val_loss: 0.5611 - val_acc: 0.8001\n",
      "Epoch 46/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.5065 - acc: 0.8147Epoch 00045: val_acc did not improve\n",
      "6480/6480 [==============================] - 66s - loss: 0.5061 - acc: 0.8148 - val_loss: 0.5483 - val_acc: 0.7921\n",
      "Epoch 47/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.4852 - acc: 0.8181Epoch 00046: val_acc improved from 0.80753 to 0.80753, saving model to weights.bestv8v3.hdf5\n",
      "6480/6480 [==============================] - 66s - loss: 0.4851 - acc: 0.8182 - val_loss: 0.6328 - val_acc: 0.8075\n",
      "Epoch 48/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.5103 - acc: 0.8233Epoch 00047: val_acc did not improve\n",
      "6480/6480 [==============================] - 66s - loss: 0.5099 - acc: 0.8236 - val_loss: 0.6092 - val_acc: 0.7866\n",
      "Epoch 49/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.4851 - acc: 0.8221Epoch 00048: val_acc improved from 0.80753 to 0.81370, saving model to weights.bestv8v3.hdf5\n",
      "6480/6480 [==============================] - 66s - loss: 0.4848 - acc: 0.8224 - val_loss: 0.5378 - val_acc: 0.8137\n",
      "Epoch 50/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.4789 - acc: 0.8272Epoch 00049: val_acc did not improve\n",
      "6480/6480 [==============================] - 66s - loss: 0.4784 - acc: 0.8272 - val_loss: 0.5379 - val_acc: 0.7964\n",
      "Epoch 51/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.4928 - acc: 0.8224Epoch 00050: val_acc did not improve\n",
      "6480/6480 [==============================] - 66s - loss: 0.4933 - acc: 0.8222 - val_loss: 1.9743 - val_acc: 0.6138\n",
      "Epoch 52/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.5048 - acc: 0.8167Epoch 00051: val_acc did not improve\n",
      "6480/6480 [==============================] - 68s - loss: 0.5070 - acc: 0.8165 - val_loss: 0.5651 - val_acc: 0.8026\n",
      "Epoch 53/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.4651 - acc: 0.8272Epoch 00052: val_acc did not improve\n",
      "6480/6480 [==============================] - 68s - loss: 0.4653 - acc: 0.8270 - val_loss: 0.6508 - val_acc: 0.7292\n",
      "Epoch 54/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.4703 - acc: 0.8243Epoch 00053: val_acc did not improve\n",
      "6480/6480 [==============================] - 68s - loss: 0.4697 - acc: 0.8247 - val_loss: 0.5207 - val_acc: 0.8007\n",
      "Epoch 55/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.4554 - acc: 0.8283Epoch 00054: val_acc did not improve\n",
      "6480/6480 [==============================] - 68s - loss: 0.4549 - acc: 0.8284 - val_loss: 0.6437 - val_acc: 0.7995\n",
      "Epoch 56/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.4405 - acc: 0.8382Epoch 00055: val_acc did not improve\n",
      "6480/6480 [==============================] - 68s - loss: 0.4399 - acc: 0.8384 - val_loss: 0.5772 - val_acc: 0.8106\n",
      "Epoch 57/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.4333 - acc: 0.8436Epoch 00056: val_acc improved from 0.81370 to 0.82418, saving model to weights.bestv8v3.hdf5\n",
      "6480/6480 [==============================] - 68s - loss: 0.4338 - acc: 0.8434 - val_loss: 0.4826 - val_acc: 0.8242\n",
      "Epoch 58/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.4784 - acc: 0.8182Epoch 00057: val_acc did not improve\n",
      "6480/6480 [==============================] - 68s - loss: 0.4783 - acc: 0.8182 - val_loss: 0.6178 - val_acc: 0.8044\n",
      "Epoch 59/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.4609 - acc: 0.8317Epoch 00058: val_acc did not improve\n",
      "6480/6480 [==============================] - 68s - loss: 0.4617 - acc: 0.8313 - val_loss: 0.5046 - val_acc: 0.8088\n",
      "Epoch 60/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.4387 - acc: 0.8403Epoch 00059: val_acc did not improve\n",
      "6480/6480 [==============================] - 67s - loss: 0.4386 - acc: 0.8404 - val_loss: 0.5986 - val_acc: 0.8131\n",
      "Epoch 61/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.4294 - acc: 0.8459Epoch 00060: val_acc did not improve\n",
      "6480/6480 [==============================] - 66s - loss: 0.4295 - acc: 0.8457 - val_loss: 1.0767 - val_acc: 0.5713\n",
      "Epoch 62/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.4345 - acc: 0.8403Epoch 00061: val_acc improved from 0.82418 to 0.83035, saving model to weights.bestv8v3.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6480/6480 [==============================] - 66s - loss: 0.4343 - acc: 0.8403 - val_loss: 0.5031 - val_acc: 0.8304\n",
      "Epoch 63/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.4279 - acc: 0.8476Epoch 00062: val_acc did not improve\n",
      "6480/6480 [==============================] - 66s - loss: 0.4282 - acc: 0.8474 - val_loss: 0.6024 - val_acc: 0.8137\n",
      "Epoch 64/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.4357 - acc: 0.8512Epoch 00063: val_acc did not improve\n",
      "6480/6480 [==============================] - 66s - loss: 0.4355 - acc: 0.8512 - val_loss: 0.5225 - val_acc: 0.8297\n",
      "Epoch 65/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.4370 - acc: 0.8453Epoch 00064: val_acc did not improve\n",
      "6480/6480 [==============================] - 66s - loss: 0.4395 - acc: 0.8452 - val_loss: 1.1079 - val_acc: 0.5182\n",
      "Epoch 66/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.4484 - acc: 0.8363Epoch 00065: val_acc did not improve\n",
      "6480/6480 [==============================] - 66s - loss: 0.4486 - acc: 0.8364 - val_loss: 0.5644 - val_acc: 0.8236\n",
      "Epoch 67/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.4208 - acc: 0.8487Epoch 00066: val_acc did not improve\n",
      "6480/6480 [==============================] - 66s - loss: 0.4206 - acc: 0.8488 - val_loss: 0.5312 - val_acc: 0.8242\n",
      "Epoch 68/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.4206 - acc: 0.8527Epoch 00067: val_acc did not improve\n",
      "6480/6480 [==============================] - 66s - loss: 0.4205 - acc: 0.8528 - val_loss: 0.5476 - val_acc: 0.8211\n",
      "Epoch 69/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.4208 - acc: 0.8524Epoch 00068: val_acc did not improve\n",
      "6480/6480 [==============================] - 66s - loss: 0.4205 - acc: 0.8525 - val_loss: 0.5172 - val_acc: 0.8118\n",
      "Epoch 70/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.4259 - acc: 0.8434Epoch 00069: val_acc did not improve\n",
      "6480/6480 [==============================] - 66s - loss: 0.4284 - acc: 0.8434 - val_loss: 0.5104 - val_acc: 0.8254\n",
      "Epoch 71/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.4031 - acc: 0.8509Epoch 00070: val_acc improved from 0.83035 to 0.83220, saving model to weights.bestv8v3.hdf5\n",
      "6480/6480 [==============================] - 67s - loss: 0.4026 - acc: 0.8511 - val_loss: 0.5269 - val_acc: 0.8322\n",
      "Epoch 72/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.4480 - acc: 0.8451Epoch 00071: val_acc did not improve\n",
      "6480/6480 [==============================] - 66s - loss: 0.4481 - acc: 0.8451 - val_loss: 0.6636 - val_acc: 0.8026\n",
      "Epoch 73/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.5267 - acc: 0.8128Epoch 00072: val_acc did not improve\n",
      "6480/6480 [==============================] - 67s - loss: 0.5261 - acc: 0.8130 - val_loss: 0.5374 - val_acc: 0.8094\n",
      "Epoch 74/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.4675 - acc: 0.8376Epoch 00073: val_acc did not improve\n",
      "6480/6480 [==============================] - 67s - loss: 0.4676 - acc: 0.8373 - val_loss: 0.5295 - val_acc: 0.8285\n",
      "Epoch 75/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.4246 - acc: 0.8524Epoch 00074: val_acc did not improve\n",
      "6480/6480 [==============================] - 67s - loss: 0.4251 - acc: 0.8520 - val_loss: 0.5811 - val_acc: 0.8075\n",
      "Epoch 76/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.4206 - acc: 0.8487Epoch 00075: val_acc improved from 0.83220 to 0.83282, saving model to weights.bestv8v3.hdf5\n",
      "6480/6480 [==============================] - 67s - loss: 0.4203 - acc: 0.8489 - val_loss: 0.5180 - val_acc: 0.8328\n",
      "Epoch 77/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.4417 - acc: 0.8451Epoch 00076: val_acc did not improve\n",
      "6480/6480 [==============================] - 66s - loss: 0.4416 - acc: 0.8451 - val_loss: 1.1114 - val_acc: 0.3948\n",
      "Epoch 78/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.4628 - acc: 0.8315Epoch 00077: val_acc did not improve\n",
      "6480/6480 [==============================] - 67s - loss: 0.4624 - acc: 0.8316 - val_loss: 0.5530 - val_acc: 0.8192\n",
      "Epoch 79/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.3984 - acc: 0.8564Epoch 00078: val_acc did not improve\n",
      "6480/6480 [==============================] - 68s - loss: 0.3983 - acc: 0.8563 - val_loss: 0.5363 - val_acc: 0.8254\n",
      "Epoch 80/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.4041 - acc: 0.8554Epoch 00079: val_acc improved from 0.83282 to 0.83467, saving model to weights.bestv8v3.hdf5\n",
      "6480/6480 [==============================] - 68s - loss: 0.4046 - acc: 0.8551 - val_loss: 0.4728 - val_acc: 0.8347\n",
      "Epoch 81/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.3920 - acc: 0.8640Epoch 00080: val_acc did not improve\n",
      "6480/6480 [==============================] - 68s - loss: 0.3918 - acc: 0.8642 - val_loss: 0.5064 - val_acc: 0.8297\n",
      "Epoch 82/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.3762 - acc: 0.8688Epoch 00081: val_acc improved from 0.83467 to 0.84454, saving model to weights.bestv8v3.hdf5\n",
      "6480/6480 [==============================] - 68s - loss: 0.3760 - acc: 0.8688 - val_loss: 0.5438 - val_acc: 0.8445\n",
      "Epoch 83/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.3746 - acc: 0.8702Epoch 00082: val_acc did not improve\n",
      "6480/6480 [==============================] - 68s - loss: 0.3748 - acc: 0.8701 - val_loss: 0.4935 - val_acc: 0.8378\n",
      "Epoch 84/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.4202 - acc: 0.8537Epoch 00083: val_acc did not improve\n",
      "6480/6480 [==============================] - 68s - loss: 0.4196 - acc: 0.8539 - val_loss: 0.5506 - val_acc: 0.8199\n",
      "Epoch 85/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.4074 - acc: 0.8577Epoch 00084: val_acc did not improve\n",
      "6480/6480 [==============================] - 68s - loss: 0.4075 - acc: 0.8576 - val_loss: 0.5375 - val_acc: 0.8260\n",
      "Epoch 86/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.4483 - acc: 0.8374Epoch 00085: val_acc did not improve\n",
      "6480/6480 [==============================] - 68s - loss: 0.4483 - acc: 0.8373 - val_loss: 1.2541 - val_acc: 0.7458\n",
      "Epoch 87/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.4497 - acc: 0.8326Epoch 00086: val_acc did not improve\n",
      "6480/6480 [==============================] - 67s - loss: 0.4508 - acc: 0.8323 - val_loss: 0.5644 - val_acc: 0.8217\n",
      "Epoch 88/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.4684 - acc: 0.8338Epoch 00087: val_acc did not improve\n",
      "6480/6480 [==============================] - 67s - loss: 0.4721 - acc: 0.8324 - val_loss: 2.0711 - val_acc: 0.2276\n",
      "Epoch 89/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 1.2785 - acc: 0.6419Epoch 00088: val_acc did not improve\n",
      "6480/6480 [==============================] - 67s - loss: 1.2771 - acc: 0.6421 - val_loss: 0.8030 - val_acc: 0.7064\n",
      "Epoch 90/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.8002 - acc: 0.7126Epoch 00089: val_acc did not improve\n",
      "6480/6480 [==============================] - 67s - loss: 0.8024 - acc: 0.7125 - val_loss: 0.7184 - val_acc: 0.7477\n",
      "Epoch 91/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.6574 - acc: 0.7489Epoch 00090: val_acc did not improve\n",
      "6480/6480 [==============================] - 67s - loss: 0.6597 - acc: 0.7489 - val_loss: 0.6487 - val_acc: 0.7810\n",
      "Epoch 92/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.6261 - acc: 0.7638Epoch 00091: val_acc did not improve\n",
      "6480/6480 [==============================] - 67s - loss: 0.6253 - acc: 0.7642 - val_loss: 0.6145 - val_acc: 0.7748\n",
      "Epoch 93/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.6199 - acc: 0.7641Epoch 00092: val_acc did not improve\n",
      "6480/6480 [==============================] - 67s - loss: 0.6195 - acc: 0.7640 - val_loss: 0.6129 - val_acc: 0.7730\n",
      "Epoch 94/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.5688 - acc: 0.7805Epoch 00093: val_acc did not improve\n",
      "6480/6480 [==============================] - 67s - loss: 0.5684 - acc: 0.7809 - val_loss: 0.5556 - val_acc: 0.7798\n",
      "Epoch 95/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.5563 - acc: 0.7888Epoch 00094: val_acc did not improve\n",
      "6480/6480 [==============================] - 67s - loss: 0.5559 - acc: 0.7889 - val_loss: 0.5505 - val_acc: 0.7970\n",
      "Epoch 96/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.5419 - acc: 0.7987Epoch 00095: val_acc did not improve\n",
      "6480/6480 [==============================] - 67s - loss: 0.5419 - acc: 0.7985 - val_loss: 0.6713 - val_acc: 0.8001\n",
      "Epoch 97/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.5372 - acc: 0.8029Epoch 00096: val_acc did not improve\n",
      "6480/6480 [==============================] - 66s - loss: 0.5368 - acc: 0.8032 - val_loss: 0.6589 - val_acc: 0.7551\n",
      "Epoch 98/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.5471 - acc: 0.7981Epoch 00097: val_acc did not improve\n",
      "6480/6480 [==============================] - 64s - loss: 0.5467 - acc: 0.7983 - val_loss: 0.5578 - val_acc: 0.8118\n",
      "Epoch 99/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.5024 - acc: 0.8226Epoch 00098: val_acc did not improve\n",
      "6480/6480 [==============================] - 65s - loss: 0.5021 - acc: 0.8227 - val_loss: 0.6545 - val_acc: 0.8205\n",
      "Epoch 100/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.4864 - acc: 0.8286Epoch 00099: val_acc did not improve\n",
      "6480/6480 [==============================] - 64s - loss: 0.4861 - acc: 0.8289 - val_loss: 0.5685 - val_acc: 0.8291\n",
      "Epoch 101/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.4459 - acc: 0.8424Epoch 00100: val_acc did not improve\n",
      "6480/6480 [==============================] - 64s - loss: 0.4464 - acc: 0.8421 - val_loss: 0.5138 - val_acc: 0.8229\n",
      "Epoch 102/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.4555 - acc: 0.8434Epoch 00101: val_acc did not improve\n",
      "6480/6480 [==============================] - 64s - loss: 0.4560 - acc: 0.8434 - val_loss: 0.5073 - val_acc: 0.8353\n",
      "Epoch 103/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.4600 - acc: 0.8450Epoch 00102: val_acc did not improve\n",
      "6480/6480 [==============================] - 64s - loss: 0.4596 - acc: 0.8451 - val_loss: 0.5354 - val_acc: 0.8223\n",
      "Epoch 104/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.4230 - acc: 0.8519Epoch 00103: val_acc did not improve\n",
      "6480/6480 [==============================] - 64s - loss: 0.4232 - acc: 0.8519 - val_loss: 0.5573 - val_acc: 0.8297\n",
      "Epoch 105/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.7397 - acc: 0.7435Epoch 00104: val_acc did not improve\n",
      "6480/6480 [==============================] - 63s - loss: 0.7418 - acc: 0.7434 - val_loss: 0.7486 - val_acc: 0.7193\n",
      "Epoch 106/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.6536 - acc: 0.7758Epoch 00105: val_acc did not improve\n",
      "6480/6480 [==============================] - 65s - loss: 0.6536 - acc: 0.7759 - val_loss: 0.7351 - val_acc: 0.7440\n",
      "Epoch 107/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.7156 - acc: 0.7325Epoch 00106: val_acc did not improve\n",
      "6480/6480 [==============================] - 64s - loss: 0.7163 - acc: 0.7321 - val_loss: 0.6252 - val_acc: 0.7563\n",
      "Epoch 108/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.5764 - acc: 0.7811Epoch 00107: val_acc did not improve\n",
      "6480/6480 [==============================] - 65s - loss: 0.5760 - acc: 0.7813 - val_loss: 0.5692 - val_acc: 0.7970\n",
      "Epoch 109/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.5510 - acc: 0.7956Epoch 00108: val_acc did not improve\n",
      "6480/6480 [==============================] - 64s - loss: 0.5509 - acc: 0.7957 - val_loss: 0.5096 - val_acc: 0.8131\n",
      "Epoch 110/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.5060 - acc: 0.8173Epoch 00109: val_acc did not improve\n",
      "6480/6480 [==============================] - 65s - loss: 0.5054 - acc: 0.8174 - val_loss: 0.5091 - val_acc: 0.8131\n",
      "Epoch 111/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.4844 - acc: 0.8207Epoch 00110: val_acc did not improve\n",
      "6480/6480 [==============================] - 64s - loss: 0.4863 - acc: 0.8207 - val_loss: 0.5105 - val_acc: 0.8100\n",
      "Epoch 112/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.4654 - acc: 0.8320Epoch 00111: val_acc did not improve\n",
      "6480/6480 [==============================] - 65s - loss: 0.4653 - acc: 0.8321 - val_loss: 0.5088 - val_acc: 0.8100\n",
      "Epoch 113/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.4472 - acc: 0.8393Epoch 00112: val_acc did not improve\n",
      "6480/6480 [==============================] - 64s - loss: 0.4468 - acc: 0.8394 - val_loss: 0.5272 - val_acc: 0.8051\n",
      "Epoch 114/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.4489 - acc: 0.8391Epoch 00113: val_acc did not improve\n",
      "6480/6480 [==============================] - 64s - loss: 0.4490 - acc: 0.8390 - val_loss: 0.5004 - val_acc: 0.8242\n",
      "Epoch 115/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.4373 - acc: 0.8413Epoch 00114: val_acc did not improve\n",
      "6480/6480 [==============================] - 64s - loss: 0.4379 - acc: 0.8412 - val_loss: 0.5388 - val_acc: 0.8125\n",
      "Epoch 116/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.4310 - acc: 0.8467Epoch 00115: val_acc did not improve\n",
      "6480/6480 [==============================] - 64s - loss: 0.4313 - acc: 0.8465 - val_loss: 0.4764 - val_acc: 0.8267\n",
      "Epoch 117/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.4195 - acc: 0.8541Epoch 00116: val_acc did not improve\n",
      "6480/6480 [==============================] - 65s - loss: 0.4201 - acc: 0.8540 - val_loss: 0.5239 - val_acc: 0.8297\n",
      "Epoch 118/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.4414 - acc: 0.8462Epoch 00117: val_acc did not improve\n",
      "6480/6480 [==============================] - 64s - loss: 0.4422 - acc: 0.8461 - val_loss: 0.7129 - val_acc: 0.7532\n",
      "Epoch 119/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.4556 - acc: 0.8496Epoch 00118: val_acc did not improve\n",
      "6480/6480 [==============================] - 64s - loss: 0.4559 - acc: 0.8492 - val_loss: 2.9145 - val_acc: 0.0796\n",
      "Epoch 120/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.5523 - acc: 0.7966Epoch 00119: val_acc did not improve\n",
      "6480/6480 [==============================] - 64s - loss: 0.5523 - acc: 0.7966 - val_loss: 0.5484 - val_acc: 0.8063\n",
      "Epoch 121/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.4919 - acc: 0.8304Epoch 00120: val_acc did not improve\n",
      "6480/6480 [==============================] - 65s - loss: 0.4919 - acc: 0.8304 - val_loss: 0.5475 - val_acc: 0.8223\n",
      "Epoch 122/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.4676 - acc: 0.8318Epoch 00121: val_acc did not improve\n",
      "6480/6480 [==============================] - 64s - loss: 0.4671 - acc: 0.8321 - val_loss: 0.5266 - val_acc: 0.8310\n",
      "Epoch 123/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.4447 - acc: 0.8396Epoch 00122: val_acc did not improve\n",
      "6480/6480 [==============================] - 65s - loss: 0.4443 - acc: 0.8398 - val_loss: 0.5910 - val_acc: 0.8254\n",
      "Epoch 124/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.4252 - acc: 0.8555Epoch 00123: val_acc did not improve\n",
      "6480/6480 [==============================] - 64s - loss: 0.4252 - acc: 0.8556 - val_loss: 0.5249 - val_acc: 0.8334\n",
      "Epoch 125/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.4643 - acc: 0.8445Epoch 00124: val_acc did not improve\n",
      "6480/6480 [==============================] - 64s - loss: 0.4644 - acc: 0.8441 - val_loss: 0.5165 - val_acc: 0.8285\n",
      "Epoch 126/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.4672 - acc: 0.8318Epoch 00125: val_acc did not improve\n",
      "6480/6480 [==============================] - 63s - loss: 0.4671 - acc: 0.8316 - val_loss: 0.5101 - val_acc: 0.8365\n",
      "Epoch 127/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.4085 - acc: 0.8584Epoch 00126: val_acc did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6480/6480 [==============================] - 63s - loss: 0.4095 - acc: 0.8582 - val_loss: 0.4840 - val_acc: 0.8267\n",
      "Epoch 128/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.4112 - acc: 0.8550Epoch 00127: val_acc did not improve\n",
      "6480/6480 [==============================] - 64s - loss: 0.4121 - acc: 0.8549 - val_loss: 0.4846 - val_acc: 0.8316\n",
      "Epoch 129/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.4003 - acc: 0.8603Epoch 00128: val_acc did not improve\n",
      "6480/6480 [==============================] - 64s - loss: 0.4000 - acc: 0.8603 - val_loss: 0.5399 - val_acc: 0.8359\n",
      "Epoch 130/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.3966 - acc: 0.8625Epoch 00129: val_acc did not improve\n",
      "6480/6480 [==============================] - 64s - loss: 0.3964 - acc: 0.8625 - val_loss: 0.4822 - val_acc: 0.8359\n",
      "Epoch 131/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.4011 - acc: 0.8567Epoch 00130: val_acc did not improve\n",
      "6480/6480 [==============================] - 64s - loss: 0.4016 - acc: 0.8565 - val_loss: 0.6088 - val_acc: 0.8322\n",
      "Epoch 132/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.3845 - acc: 0.8659Epoch 00131: val_acc did not improve\n",
      "6480/6480 [==============================] - 64s - loss: 0.3856 - acc: 0.8656 - val_loss: 0.5912 - val_acc: 0.8322\n",
      "Epoch 133/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.4664 - acc: 0.8453Epoch 00132: val_acc did not improve\n",
      "6480/6480 [==============================] - 63s - loss: 0.4687 - acc: 0.8451 - val_loss: 0.5216 - val_acc: 0.8316\n",
      "Epoch 134/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.4176 - acc: 0.8646Epoch 00133: val_acc did not improve\n",
      "6480/6480 [==============================] - 64s - loss: 0.4170 - acc: 0.8648 - val_loss: 0.5451 - val_acc: 0.8297\n",
      "Epoch 135/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.3916 - acc: 0.8640Epoch 00134: val_acc did not improve\n",
      "6480/6480 [==============================] - 64s - loss: 0.3911 - acc: 0.8642 - val_loss: 0.4792 - val_acc: 0.8291\n",
      "Epoch 136/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.3910 - acc: 0.8642Epoch 00135: val_acc did not improve\n",
      "6480/6480 [==============================] - 63s - loss: 0.3916 - acc: 0.8639 - val_loss: 0.5636 - val_acc: 0.7896\n",
      "Epoch 137/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.3995 - acc: 0.8597Epoch 00136: val_acc did not improve\n",
      "6480/6480 [==============================] - 64s - loss: 0.3991 - acc: 0.8599 - val_loss: 0.5503 - val_acc: 0.8322\n",
      "Epoch 138/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.3839 - acc: 0.8657Epoch 00137: val_acc did not improve\n",
      "6480/6480 [==============================] - 63s - loss: 0.3832 - acc: 0.8660 - val_loss: 0.5516 - val_acc: 0.8260\n",
      "Epoch 139/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.3792 - acc: 0.8707Epoch 00138: val_acc did not improve\n",
      "6480/6480 [==============================] - 63s - loss: 0.3797 - acc: 0.8705 - val_loss: 0.4879 - val_acc: 0.8322\n",
      "Epoch 140/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.3647 - acc: 0.8748Epoch 00139: val_acc did not improve\n",
      "6480/6480 [==============================] - 63s - loss: 0.3646 - acc: 0.8750 - val_loss: 0.4976 - val_acc: 0.8248\n",
      "Epoch 141/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.3637 - acc: 0.8769Epoch 00140: val_acc did not improve\n",
      "6480/6480 [==============================] - 63s - loss: 0.3630 - acc: 0.8772 - val_loss: 0.4666 - val_acc: 0.8359\n",
      "Epoch 142/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.3739 - acc: 0.8735Epoch 00141: val_acc did not improve\n",
      "6480/6480 [==============================] - 64s - loss: 0.3733 - acc: 0.8738 - val_loss: 0.4937 - val_acc: 0.8427\n",
      "Epoch 143/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.3456 - acc: 0.8772Epoch 00142: val_acc improved from 0.84454 to 0.84454, saving model to weights.bestv8v3.hdf5\n",
      "6480/6480 [==============================] - 64s - loss: 0.3454 - acc: 0.8770 - val_loss: 0.5162 - val_acc: 0.8445\n",
      "Epoch 144/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.3563 - acc: 0.8782Epoch 00143: val_acc did not improve\n",
      "6480/6480 [==============================] - 63s - loss: 0.3572 - acc: 0.8778 - val_loss: 0.5755 - val_acc: 0.8328\n",
      "Epoch 145/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.3826 - acc: 0.8666Epoch 00144: val_acc did not improve\n",
      "6480/6480 [==============================] - 64s - loss: 0.3828 - acc: 0.8665 - val_loss: 0.4874 - val_acc: 0.8390\n",
      "Epoch 146/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.3572 - acc: 0.8820Epoch 00145: val_acc did not improve\n",
      "6480/6480 [==============================] - 63s - loss: 0.3571 - acc: 0.8821 - val_loss: 0.4928 - val_acc: 0.8439\n",
      "Epoch 147/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.3626 - acc: 0.8745Epoch 00146: val_acc improved from 0.84454 to 0.84516, saving model to weights.bestv8v3.hdf5\n",
      "6480/6480 [==============================] - 64s - loss: 0.3625 - acc: 0.8744 - val_loss: 0.5392 - val_acc: 0.8452\n",
      "Epoch 148/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.3382 - acc: 0.8832Epoch 00147: val_acc did not improve\n",
      "6480/6480 [==============================] - 63s - loss: 0.3378 - acc: 0.8833 - val_loss: 0.4980 - val_acc: 0.8433\n",
      "Epoch 149/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.3283 - acc: 0.8864Epoch 00148: val_acc improved from 0.84516 to 0.84824, saving model to weights.bestv8v3.hdf5\n",
      "6480/6480 [==============================] - 64s - loss: 0.3285 - acc: 0.8863 - val_loss: 0.5544 - val_acc: 0.8482\n",
      "Epoch 150/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.3667 - acc: 0.8736Epoch 00149: val_acc did not improve\n",
      "6480/6480 [==============================] - 64s - loss: 0.3666 - acc: 0.8736 - val_loss: 0.5349 - val_acc: 0.8408\n",
      "Epoch 151/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.3508 - acc: 0.8846Epoch 00150: val_acc did not improve\n",
      "6480/6480 [==============================] - 64s - loss: 0.3502 - acc: 0.8849 - val_loss: 0.5297 - val_acc: 0.8464\n",
      "Epoch 152/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.3550 - acc: 0.8770Epoch 00151: val_acc did not improve\n",
      "6480/6480 [==============================] - 66s - loss: 0.3553 - acc: 0.8770 - val_loss: 0.6970 - val_acc: 0.8112\n",
      "Epoch 153/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.3667 - acc: 0.8700Epoch 00152: val_acc did not improve\n",
      "6480/6480 [==============================] - 66s - loss: 0.3689 - acc: 0.8694 - val_loss: 0.5132 - val_acc: 0.8285\n",
      "Epoch 154/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.3503 - acc: 0.8820Epoch 00153: val_acc improved from 0.84824 to 0.85133, saving model to weights.bestv8v3.hdf5\n",
      "6480/6480 [==============================] - 109s - loss: 0.3501 - acc: 0.8819 - val_loss: 0.5282 - val_acc: 0.8513\n",
      "Epoch 155/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.4675 - acc: 0.8309Epoch 00154: val_acc did not improve\n",
      "6480/6480 [==============================] - 66s - loss: 0.4675 - acc: 0.8309 - val_loss: 0.5864 - val_acc: 0.8162\n",
      "Epoch 156/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.4384 - acc: 0.8547Epoch 00155: val_acc did not improve\n",
      "6480/6480 [==============================] - 66s - loss: 0.4383 - acc: 0.8546 - val_loss: 0.5643 - val_acc: 0.8322\n",
      "Epoch 157/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.3731 - acc: 0.8762Epoch 00156: val_acc did not improve\n",
      "6480/6480 [==============================] - 66s - loss: 0.3738 - acc: 0.8759 - val_loss: 0.5264 - val_acc: 0.8334\n",
      "Epoch 158/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.3611 - acc: 0.8748Epoch 00157: val_acc did not improve\n",
      "6480/6480 [==============================] - 66s - loss: 0.3615 - acc: 0.8747 - val_loss: 0.5865 - val_acc: 0.8433\n",
      "Epoch 159/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.3307 - acc: 0.8900Epoch 00158: val_acc did not improve\n",
      "6480/6480 [==============================] - 66s - loss: 0.3305 - acc: 0.8900 - val_loss: 0.5688 - val_acc: 0.8452\n",
      "Epoch 160/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.3377 - acc: 0.8886Epoch 00159: val_acc improved from 0.85133 to 0.85503, saving model to weights.bestv8v3.hdf5\n",
      "6480/6480 [==============================] - 65s - loss: 0.3375 - acc: 0.8886 - val_loss: 0.5213 - val_acc: 0.8550\n",
      "Epoch 161/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.3237 - acc: 0.8881Epoch 00160: val_acc did not improve\n",
      "6480/6480 [==============================] - 63s - loss: 0.3234 - acc: 0.8884 - val_loss: 0.5708 - val_acc: 0.8501\n",
      "Epoch 162/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.9043 - acc: 0.8297Epoch 00161: val_acc did not improve\n",
      "6480/6480 [==============================] - 64s - loss: 0.9035 - acc: 0.8295 - val_loss: 1.0255 - val_acc: 0.7421\n",
      "Epoch 163/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.4688 - acc: 0.8368Epoch 00162: val_acc did not improve\n",
      "6480/6480 [==============================] - 68s - loss: 0.4683 - acc: 0.8370 - val_loss: 0.5934 - val_acc: 0.8279\n",
      "Epoch 164/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.3996 - acc: 0.8598Epoch 00163: val_acc did not improve\n",
      "6480/6480 [==============================] - 68s - loss: 0.4018 - acc: 0.8599 - val_loss: 0.5991 - val_acc: 0.8433\n",
      "Epoch 165/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.3608 - acc: 0.8730Epoch 00164: val_acc did not improve\n",
      "6480/6480 [==============================] - 68s - loss: 0.3607 - acc: 0.8730 - val_loss: 0.6026 - val_acc: 0.8489\n",
      "Epoch 166/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.3556 - acc: 0.8762Epoch 00165: val_acc did not improve\n",
      "6480/6480 [==============================] - 68s - loss: 0.3554 - acc: 0.8764 - val_loss: 0.5064 - val_acc: 0.8458\n",
      "Epoch 167/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.3362 - acc: 0.8846Epoch 00166: val_acc did not improve\n",
      "6480/6480 [==============================] - 66s - loss: 0.3359 - acc: 0.8847 - val_loss: 0.5639 - val_acc: 0.8513\n",
      "Epoch 168/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.3422 - acc: 0.8813Epoch 00167: val_acc did not improve\n",
      "6480/6480 [==============================] - 63s - loss: 0.3416 - acc: 0.8816 - val_loss: 0.5148 - val_acc: 0.8464\n",
      "Epoch 169/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.3225 - acc: 0.8888Epoch 00168: val_acc did not improve\n",
      "6480/6480 [==============================] - 65s - loss: 0.3223 - acc: 0.8889 - val_loss: 0.5038 - val_acc: 0.8519\n",
      "Epoch 170/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.3396 - acc: 0.8830Epoch 00169: val_acc did not improve\n",
      "6480/6480 [==============================] - 65s - loss: 0.3394 - acc: 0.8830 - val_loss: 0.5453 - val_acc: 0.8094\n",
      "Epoch 171/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.3369 - acc: 0.8851Epoch 00170: val_acc did not improve\n",
      "6480/6480 [==============================] - 66s - loss: 0.3374 - acc: 0.8850 - val_loss: 0.5531 - val_acc: 0.8452\n",
      "Epoch 172/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.3321 - acc: 0.8868Epoch 00171: val_acc did not improve\n",
      "6480/6480 [==============================] - 65s - loss: 0.3321 - acc: 0.8867 - val_loss: 0.5765 - val_acc: 0.8495\n",
      "Epoch 173/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.3211 - acc: 0.8985Epoch 00172: val_acc did not improve\n",
      "6480/6480 [==============================] - 65s - loss: 0.3208 - acc: 0.8986 - val_loss: 0.7696 - val_acc: 0.6687\n",
      "Epoch 174/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.3326 - acc: 0.8877Epoch 00173: val_acc did not improve\n",
      "6480/6480 [==============================] - 65s - loss: 0.3324 - acc: 0.8877 - val_loss: 0.5305 - val_acc: 0.8415\n",
      "Epoch 175/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.3116 - acc: 0.8953Epoch 00174: val_acc did not improve\n",
      "6480/6480 [==============================] - 66s - loss: 0.3112 - acc: 0.8955 - val_loss: 0.5522 - val_acc: 0.8495\n",
      "Epoch 176/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.2973 - acc: 0.8982Epoch 00175: val_acc did not improve\n",
      "6480/6480 [==============================] - 66s - loss: 0.2977 - acc: 0.8981 - val_loss: 0.6066 - val_acc: 0.8544\n",
      "Epoch 177/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.3041 - acc: 0.8985Epoch 00176: val_acc did not improve\n",
      "6480/6480 [==============================] - 66s - loss: 0.3038 - acc: 0.8986 - val_loss: 0.5460 - val_acc: 0.8415\n",
      "Epoch 178/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.3035 - acc: 0.8977Epoch 00177: val_acc did not improve\n",
      "6480/6480 [==============================] - 64s - loss: 0.3030 - acc: 0.8978 - val_loss: 0.5426 - val_acc: 0.8402\n",
      "Epoch 179/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.3604 - acc: 0.8796Epoch 00178: val_acc did not improve\n",
      "6480/6480 [==============================] - 63s - loss: 0.3609 - acc: 0.8795 - val_loss: 0.6949 - val_acc: 0.8186\n",
      "Epoch 180/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.3302 - acc: 0.8903Epoch 00179: val_acc did not improve\n",
      "6480/6480 [==============================] - 63s - loss: 0.3302 - acc: 0.8904 - val_loss: 0.4672 - val_acc: 0.8433\n",
      "Epoch 181/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.3125 - acc: 0.8946Epoch 00180: val_acc did not improve\n",
      "6480/6480 [==============================] - 63s - loss: 0.3136 - acc: 0.8943 - val_loss: 0.5578 - val_acc: 0.8452\n",
      "Epoch 182/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.3165 - acc: 0.9005Epoch 00181: val_acc did not improve\n",
      "6480/6480 [==============================] - 63s - loss: 0.3159 - acc: 0.9006 - val_loss: 0.5536 - val_acc: 0.8359\n",
      "Epoch 183/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.3068 - acc: 0.8973Epoch 00182: val_acc did not improve\n",
      "6480/6480 [==============================] - 63s - loss: 0.3067 - acc: 0.8974 - val_loss: 0.5781 - val_acc: 0.8408\n",
      "Epoch 184/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.3004 - acc: 0.8990Epoch 00183: val_acc did not improve\n",
      "6480/6480 [==============================] - 63s - loss: 0.3019 - acc: 0.8980 - val_loss: 0.5609 - val_acc: 0.8452\n",
      "Epoch 185/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.2884 - acc: 0.9015Epoch 00184: val_acc did not improve\n",
      "6480/6480 [==============================] - 64s - loss: 0.2885 - acc: 0.9012 - val_loss: 0.5783 - val_acc: 0.8464\n",
      "Epoch 186/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.0301 - acc: 0.6188Epoch 00185: val_acc did not improve\n",
      "6480/6480 [==============================] - 63s - loss: 0.0301 - acc: 0.6188 - val_loss: 1.1921e-07 - val_acc: 0.6046\n",
      "Epoch 187/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 1.1921e-07 - acc: 0.5879Epoch 00186: val_acc did not improve\n",
      "6480/6480 [==============================] - 63s - loss: 1.1921e-07 - acc: 0.5877 - val_loss: 1.1921e-07 - val_acc: 0.6046\n",
      "Epoch 188/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 1.1921e-07 - acc: 0.5873Epoch 00187: val_acc did not improve\n",
      "6480/6480 [==============================] - 63s - loss: 1.1921e-07 - acc: 0.5877 - val_loss: 1.1921e-07 - val_acc: 0.6046\n",
      "Epoch 189/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 1.1921e-07 - acc: 0.5874Epoch 00188: val_acc did not improve\n",
      "6480/6480 [==============================] - 63s - loss: 1.1921e-07 - acc: 0.5877 - val_loss: 1.1921e-07 - val_acc: 0.6046\n",
      "Epoch 190/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 1.1921e-07 - acc: 0.5879Epoch 00189: val_acc did not improve\n",
      "6480/6480 [==============================] - 63s - loss: 1.1921e-07 - acc: 0.5877 - val_loss: 1.1921e-07 - val_acc: 0.6046\n",
      "Epoch 191/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 1.1921e-07 - acc: 0.5874Epoch 00190: val_acc did not improve\n",
      "6480/6480 [==============================] - 63s - loss: 1.1921e-07 - acc: 0.5877 - val_loss: 1.1921e-07 - val_acc: 0.6046\n",
      "Epoch 192/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6464/6480 [============================>.] - ETA: 0s - loss: 1.1921e-07 - acc: 0.5873Epoch 00191: val_acc did not improve\n",
      "6480/6480 [==============================] - 64s - loss: 1.1921e-07 - acc: 0.5877 - val_loss: 1.1921e-07 - val_acc: 0.6046\n",
      "Epoch 193/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 1.1921e-07 - acc: 0.5880Epoch 00192: val_acc did not improve\n",
      "6480/6480 [==============================] - 64s - loss: 1.1921e-07 - acc: 0.5877 - val_loss: 1.1921e-07 - val_acc: 0.6046\n",
      "Epoch 194/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 1.1921e-07 - acc: 0.5877Epoch 00193: val_acc did not improve\n",
      "6480/6480 [==============================] - 63s - loss: 1.1921e-07 - acc: 0.5877 - val_loss: 1.1921e-07 - val_acc: 0.6046\n",
      "Epoch 195/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 1.1921e-07 - acc: 0.5876Epoch 00194: val_acc did not improve\n",
      "6480/6480 [==============================] - 63s - loss: 1.1921e-07 - acc: 0.5877 - val_loss: 1.1921e-07 - val_acc: 0.6046\n",
      "Epoch 196/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 1.1921e-07 - acc: 0.5876Epoch 00195: val_acc did not improve\n",
      "6480/6480 [==============================] - 63s - loss: 1.1921e-07 - acc: 0.5877 - val_loss: 1.1921e-07 - val_acc: 0.6046\n",
      "Epoch 197/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 1.1921e-07 - acc: 0.5876Epoch 00196: val_acc did not improve\n",
      "6480/6480 [==============================] - 63s - loss: 1.1921e-07 - acc: 0.5877 - val_loss: 1.1921e-07 - val_acc: 0.6046\n",
      "Epoch 198/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 1.1921e-07 - acc: 0.5882Epoch 00197: val_acc did not improve\n",
      "6480/6480 [==============================] - 63s - loss: 1.1921e-07 - acc: 0.5877 - val_loss: 1.1921e-07 - val_acc: 0.6046\n",
      "Epoch 199/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 1.1921e-07 - acc: 0.5880Epoch 00198: val_acc did not improve\n",
      "6480/6480 [==============================] - 63s - loss: 1.1921e-07 - acc: 0.5877 - val_loss: 1.1921e-07 - val_acc: 0.6046\n",
      "Epoch 200/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 1.1921e-07 - acc: 0.5876Epoch 00199: val_acc did not improve\n",
      "6480/6480 [==============================] - 63s - loss: 1.1921e-07 - acc: 0.5877 - val_loss: 1.1921e-07 - val_acc: 0.6046\n",
      "Epoch 201/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 1.1921e-07 - acc: 0.5871Epoch 00200: val_acc did not improve\n",
      "6480/6480 [==============================] - 63s - loss: 1.1921e-07 - acc: 0.5877 - val_loss: 1.1921e-07 - val_acc: 0.6046\n",
      "Epoch 202/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 1.1921e-07 - acc: 0.5879Epoch 00201: val_acc did not improve\n",
      "6480/6480 [==============================] - 64s - loss: 1.1921e-07 - acc: 0.5877 - val_loss: 1.1921e-07 - val_acc: 0.6046\n",
      "Epoch 203/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 1.1921e-07 - acc: 0.5879Epoch 00202: val_acc did not improve\n",
      "6480/6480 [==============================] - 64s - loss: 1.1921e-07 - acc: 0.5877 - val_loss: 1.1921e-07 - val_acc: 0.6046\n",
      "Epoch 204/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 1.1921e-07 - acc: 0.5876Epoch 00203: val_acc did not improve\n",
      "6480/6480 [==============================] - 63s - loss: 1.1921e-07 - acc: 0.5877 - val_loss: 1.1921e-07 - val_acc: 0.6046\n",
      "Epoch 205/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 1.1921e-07 - acc: 0.5877Epoch 00204: val_acc did not improve\n",
      "6480/6480 [==============================] - 63s - loss: 1.1921e-07 - acc: 0.5877 - val_loss: 1.1921e-07 - val_acc: 0.6046\n",
      "Epoch 206/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 1.1921e-07 - acc: 0.5871Epoch 00205: val_acc did not improve\n",
      "6480/6480 [==============================] - 63s - loss: 1.1921e-07 - acc: 0.5877 - val_loss: 1.1921e-07 - val_acc: 0.6046\n",
      "Epoch 207/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 1.1921e-07 - acc: 0.5873Epoch 00206: val_acc did not improve\n",
      "6480/6480 [==============================] - 63s - loss: 1.1921e-07 - acc: 0.5877 - val_loss: 1.1921e-07 - val_acc: 0.6046\n",
      "Epoch 208/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 1.1921e-07 - acc: 0.5879Epoch 00207: val_acc did not improve\n",
      "6480/6480 [==============================] - 64s - loss: 1.1921e-07 - acc: 0.5877 - val_loss: 1.1921e-07 - val_acc: 0.6046\n",
      "Epoch 209/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 1.1921e-07 - acc: 0.5879Epoch 00208: val_acc did not improve\n",
      "6480/6480 [==============================] - 63s - loss: 1.1921e-07 - acc: 0.5877 - val_loss: 1.1921e-07 - val_acc: 0.6046\n",
      "Epoch 210/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 1.1921e-07 - acc: 0.5882Epoch 00209: val_acc did not improve\n",
      "6480/6480 [==============================] - 63s - loss: 1.1921e-07 - acc: 0.5877 - val_loss: 1.1921e-07 - val_acc: 0.6046\n",
      "Epoch 211/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 1.1921e-07 - acc: 0.5873Epoch 00210: val_acc did not improve\n",
      "6480/6480 [==============================] - 64s - loss: 1.1921e-07 - acc: 0.5877 - val_loss: 1.1921e-07 - val_acc: 0.6046\n",
      "Epoch 212/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 1.1921e-07 - acc: 0.5873Epoch 00211: val_acc did not improve\n",
      "6480/6480 [==============================] - 63s - loss: 1.1921e-07 - acc: 0.5877 - val_loss: 1.1921e-07 - val_acc: 0.6046\n",
      "Epoch 213/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 1.1921e-07 - acc: 0.5873Epoch 00212: val_acc did not improve\n",
      "6480/6480 [==============================] - 64s - loss: 1.1921e-07 - acc: 0.5877 - val_loss: 1.1921e-07 - val_acc: 0.6046\n",
      "Epoch 214/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 1.1921e-07 - acc: 0.5876Epoch 00213: val_acc did not improve\n",
      "6480/6480 [==============================] - 64s - loss: 1.1921e-07 - acc: 0.5877 - val_loss: 1.1921e-07 - val_acc: 0.6046\n",
      "Epoch 215/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 1.1921e-07 - acc: 0.5873Epoch 00214: val_acc did not improve\n",
      "6480/6480 [==============================] - 64s - loss: 1.1921e-07 - acc: 0.5877 - val_loss: 1.1921e-07 - val_acc: 0.6046\n",
      "Epoch 216/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 1.1921e-07 - acc: 0.5877Epoch 00215: val_acc did not improve\n",
      "6480/6480 [==============================] - 64s - loss: 1.1921e-07 - acc: 0.5877 - val_loss: 1.1921e-07 - val_acc: 0.6046\n",
      "Epoch 217/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 1.1921e-07 - acc: 0.5877Epoch 00216: val_acc did not improve\n",
      "6480/6480 [==============================] - 63s - loss: 1.1921e-07 - acc: 0.5877 - val_loss: 1.1921e-07 - val_acc: 0.6046\n",
      "Epoch 218/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 1.1921e-07 - acc: 0.5877Epoch 00217: val_acc did not improve\n",
      "6480/6480 [==============================] - 63s - loss: 1.1921e-07 - acc: 0.5877 - val_loss: 1.1921e-07 - val_acc: 0.6046\n",
      "Epoch 219/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 1.1921e-07 - acc: 0.5874Epoch 00218: val_acc did not improve\n",
      "6480/6480 [==============================] - 64s - loss: 1.1921e-07 - acc: 0.5877 - val_loss: 1.1921e-07 - val_acc: 0.6046\n",
      "Epoch 220/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 1.1921e-07 - acc: 0.5874Epoch 00219: val_acc did not improve\n",
      "6480/6480 [==============================] - 63s - loss: 1.1921e-07 - acc: 0.5877 - val_loss: 1.1921e-07 - val_acc: 0.6046\n",
      "Epoch 221/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 1.1921e-07 - acc: 0.5880Epoch 00220: val_acc did not improve\n",
      "6480/6480 [==============================] - 63s - loss: 1.1921e-07 - acc: 0.5877 - val_loss: 1.1921e-07 - val_acc: 0.6046\n",
      "Epoch 222/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 1.1921e-07 - acc: 0.5876Epoch 00221: val_acc did not improve\n",
      "6480/6480 [==============================] - 63s - loss: 1.1921e-07 - acc: 0.5877 - val_loss: 1.1921e-07 - val_acc: 0.6046\n",
      "Epoch 223/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 1.1921e-07 - acc: 0.5883Epoch 00222: val_acc did not improve\n",
      "6480/6480 [==============================] - 64s - loss: 1.1921e-07 - acc: 0.5877 - val_loss: 1.1921e-07 - val_acc: 0.6046\n",
      "Epoch 224/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 1.1921e-07 - acc: 0.5874Epoch 00223: val_acc did not improve\n",
      "6480/6480 [==============================] - 63s - loss: 1.1921e-07 - acc: 0.5877 - val_loss: 1.1921e-07 - val_acc: 0.6046\n",
      "Epoch 225/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 1.1921e-07 - acc: 0.5876Epoch 00224: val_acc did not improve\n",
      "6480/6480 [==============================] - 64s - loss: 1.1921e-07 - acc: 0.5877 - val_loss: 1.1921e-07 - val_acc: 0.6046\n",
      "Epoch 226/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 1.1921e-07 - acc: 0.5876Epoch 00225: val_acc did not improve\n",
      "6480/6480 [==============================] - 65s - loss: 1.1921e-07 - acc: 0.5877 - val_loss: 1.1921e-07 - val_acc: 0.6046\n",
      "Epoch 227/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 1.1921e-07 - acc: 0.5873Epoch 00226: val_acc did not improve\n",
      "6480/6480 [==============================] - 64s - loss: 1.1921e-07 - acc: 0.5877 - val_loss: 1.1921e-07 - val_acc: 0.6046\n",
      "Epoch 228/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 1.1921e-07 - acc: 0.5876Epoch 00227: val_acc did not improve\n",
      "6480/6480 [==============================] - 65s - loss: 1.1921e-07 - acc: 0.5877 - val_loss: 1.1921e-07 - val_acc: 0.6046\n",
      "Epoch 229/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 1.1921e-07 - acc: 0.5876Epoch 00228: val_acc did not improve\n",
      "6480/6480 [==============================] - 65s - loss: 1.1921e-07 - acc: 0.5877 - val_loss: 1.1921e-07 - val_acc: 0.6046\n",
      "Epoch 230/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 1.1921e-07 - acc: 0.5876Epoch 00229: val_acc did not improve\n",
      "6480/6480 [==============================] - 65s - loss: 1.1921e-07 - acc: 0.5877 - val_loss: 1.1921e-07 - val_acc: 0.6046\n",
      "Epoch 231/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 1.1921e-07 - acc: 0.5876Epoch 00230: val_acc did not improve\n",
      "6480/6480 [==============================] - 65s - loss: 1.1921e-07 - acc: 0.5877 - val_loss: 1.1921e-07 - val_acc: 0.6046\n",
      "Epoch 232/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 1.1921e-07 - acc: 0.5871Epoch 00231: val_acc did not improve\n",
      "6480/6480 [==============================] - 65s - loss: 1.1921e-07 - acc: 0.5877 - val_loss: 1.1921e-07 - val_acc: 0.6046\n",
      "Epoch 233/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 1.1921e-07 - acc: 0.5877Epoch 00232: val_acc did not improve\n",
      "6480/6480 [==============================] - 65s - loss: 1.1921e-07 - acc: 0.5877 - val_loss: 1.1921e-07 - val_acc: 0.6046\n",
      "Epoch 234/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 1.1921e-07 - acc: 0.5880Epoch 00233: val_acc did not improve\n",
      "6480/6480 [==============================] - 64s - loss: 1.1921e-07 - acc: 0.5877 - val_loss: 1.1921e-07 - val_acc: 0.6046\n",
      "Epoch 235/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 1.1921e-07 - acc: 0.5873Epoch 00234: val_acc did not improve\n",
      "6480/6480 [==============================] - 63s - loss: 1.1921e-07 - acc: 0.5877 - val_loss: 1.1921e-07 - val_acc: 0.6046\n",
      "Epoch 236/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 1.1921e-07 - acc: 0.5869Epoch 00235: val_acc did not improve\n",
      "6480/6480 [==============================] - 63s - loss: 1.1921e-07 - acc: 0.5877 - val_loss: 1.1921e-07 - val_acc: 0.6046\n",
      "Epoch 237/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 1.1921e-07 - acc: 0.5880Epoch 00236: val_acc did not improve\n",
      "6480/6480 [==============================] - 63s - loss: 1.1921e-07 - acc: 0.5877 - val_loss: 1.1921e-07 - val_acc: 0.6046\n",
      "Epoch 238/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 1.1921e-07 - acc: 0.5879Epoch 00237: val_acc did not improve\n",
      "6480/6480 [==============================] - 63s - loss: 1.1921e-07 - acc: 0.5877 - val_loss: 1.1921e-07 - val_acc: 0.6046\n",
      "Epoch 239/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 1.1921e-07 - acc: 0.5882Epoch 00238: val_acc did not improve\n",
      "6480/6480 [==============================] - 64s - loss: 1.1921e-07 - acc: 0.5877 - val_loss: 1.1921e-07 - val_acc: 0.6046\n",
      "Epoch 240/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 1.1921e-07 - acc: 0.5882Epoch 00239: val_acc did not improve\n",
      "6480/6480 [==============================] - 64s - loss: 1.1921e-07 - acc: 0.5877 - val_loss: 1.1921e-07 - val_acc: 0.6046\n",
      "Epoch 241/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 1.1921e-07 - acc: 0.5879Epoch 00240: val_acc did not improve\n",
      "6480/6480 [==============================] - 63s - loss: 1.1921e-07 - acc: 0.5877 - val_loss: 1.1921e-07 - val_acc: 0.6046\n",
      "Epoch 242/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 1.1921e-07 - acc: 0.5877Epoch 00241: val_acc did not improve\n",
      "6480/6480 [==============================] - 63s - loss: 1.1921e-07 - acc: 0.5877 - val_loss: 1.1921e-07 - val_acc: 0.6046\n",
      "Epoch 243/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 1.1921e-07 - acc: 0.5876Epoch 00242: val_acc did not improve\n",
      "6480/6480 [==============================] - 64s - loss: 1.1921e-07 - acc: 0.5877 - val_loss: 1.1921e-07 - val_acc: 0.6046\n",
      "Epoch 244/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 1.1921e-07 - acc: 0.5883Epoch 00243: val_acc did not improve\n",
      "6480/6480 [==============================] - 63s - loss: 1.1921e-07 - acc: 0.5877 - val_loss: 1.1921e-07 - val_acc: 0.6046\n",
      "Epoch 245/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 1.1921e-07 - acc: 0.5874Epoch 00244: val_acc did not improve\n",
      "6480/6480 [==============================] - 63s - loss: 1.1921e-07 - acc: 0.5877 - val_loss: 1.1921e-07 - val_acc: 0.6046\n",
      "Epoch 246/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 1.1921e-07 - acc: 0.5874Epoch 00245: val_acc did not improve\n",
      "6480/6480 [==============================] - 64s - loss: 1.1921e-07 - acc: 0.5877 - val_loss: 1.1921e-07 - val_acc: 0.6046\n",
      "Epoch 247/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 1.1921e-07 - acc: 0.5874Epoch 00246: val_acc did not improve\n",
      "6480/6480 [==============================] - 63s - loss: 1.1921e-07 - acc: 0.5877 - val_loss: 1.1921e-07 - val_acc: 0.6046\n",
      "Epoch 248/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 1.1921e-07 - acc: 0.5876Epoch 00247: val_acc did not improve\n",
      "6480/6480 [==============================] - 63s - loss: 1.1921e-07 - acc: 0.5877 - val_loss: 1.1921e-07 - val_acc: 0.6046\n",
      "Epoch 249/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 1.1921e-07 - acc: 0.5882Epoch 00248: val_acc did not improve\n",
      "6480/6480 [==============================] - 63s - loss: 1.1921e-07 - acc: 0.5877 - val_loss: 1.1921e-07 - val_acc: 0.6046\n",
      "Epoch 250/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 1.1921e-07 - acc: 0.5877Epoch 00249: val_acc did not improve\n",
      "6480/6480 [==============================] - 64s - loss: 1.1921e-07 - acc: 0.5877 - val_loss: 1.1921e-07 - val_acc: 0.6046\n",
      "Epoch 251/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 1.1921e-07 - acc: 0.5882Epoch 00250: val_acc did not improve\n",
      "6480/6480 [==============================] - 63s - loss: 1.1921e-07 - acc: 0.5877 - val_loss: 1.1921e-07 - val_acc: 0.6046\n",
      "Epoch 252/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 1.1921e-07 - acc: 0.5871Epoch 00251: val_acc did not improve\n",
      "6480/6480 [==============================] - 63s - loss: 1.1921e-07 - acc: 0.5877 - val_loss: 1.1921e-07 - val_acc: 0.6046\n",
      "Epoch 253/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 1.1921e-07 - acc: 0.5874Epoch 00252: val_acc did not improve\n",
      "6480/6480 [==============================] - 63s - loss: 1.1921e-07 - acc: 0.5877 - val_loss: 1.1921e-07 - val_acc: 0.6046\n",
      "Epoch 254/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 1.1921e-07 - acc: 0.5876Epoch 00253: val_acc did not improve\n",
      "6480/6480 [==============================] - 63s - loss: 1.1921e-07 - acc: 0.5877 - val_loss: 1.1921e-07 - val_acc: 0.6046\n",
      "Epoch 255/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6464/6480 [============================>.] - ETA: 0s - loss: 1.1921e-07 - acc: 0.5873Epoch 00254: val_acc did not improve\n",
      "6480/6480 [==============================] - 64s - loss: 1.1921e-07 - acc: 0.5877 - val_loss: 1.1921e-07 - val_acc: 0.6046\n",
      "Epoch 256/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 1.1921e-07 - acc: 0.5879Epoch 00255: val_acc did not improve\n",
      "6480/6480 [==============================] - 63s - loss: 1.1921e-07 - acc: 0.5877 - val_loss: 1.1921e-07 - val_acc: 0.6046\n",
      "Epoch 257/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 1.1921e-07 - acc: 0.5876Epoch 00256: val_acc did not improve\n",
      "6480/6480 [==============================] - 64s - loss: 1.1921e-07 - acc: 0.5877 - val_loss: 1.1921e-07 - val_acc: 0.6046\n",
      "Epoch 258/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 1.1921e-07 - acc: 0.5873Epoch 00257: val_acc did not improve\n",
      "6480/6480 [==============================] - 63s - loss: 1.1921e-07 - acc: 0.5877 - val_loss: 1.1921e-07 - val_acc: 0.6046\n",
      "Epoch 259/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 1.1921e-07 - acc: 0.5874Epoch 00258: val_acc did not improve\n",
      "6480/6480 [==============================] - 63s - loss: 1.1921e-07 - acc: 0.5877 - val_loss: 1.1921e-07 - val_acc: 0.6046\n",
      "Epoch 260/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 1.1921e-07 - acc: 0.5876Epoch 00259: val_acc did not improve\n",
      "6480/6480 [==============================] - 64s - loss: 1.1921e-07 - acc: 0.5877 - val_loss: 1.1921e-07 - val_acc: 0.6046\n",
      "Epoch 261/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 1.1921e-07 - acc: 0.5876Epoch 00260: val_acc did not improve\n",
      "6480/6480 [==============================] - 63s - loss: 1.1921e-07 - acc: 0.5877 - val_loss: 1.1921e-07 - val_acc: 0.6046\n",
      "Epoch 262/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 1.1921e-07 - acc: 0.5874Epoch 00261: val_acc did not improve\n",
      "6480/6480 [==============================] - 64s - loss: 1.1921e-07 - acc: 0.5877 - val_loss: 1.1921e-07 - val_acc: 0.6046\n",
      "Epoch 263/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 1.1921e-07 - acc: 0.5874Epoch 00262: val_acc did not improve\n",
      "6480/6480 [==============================] - 66s - loss: 1.1921e-07 - acc: 0.5877 - val_loss: 1.1921e-07 - val_acc: 0.6046\n",
      "Epoch 264/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 1.1921e-07 - acc: 0.5877Epoch 00263: val_acc did not improve\n",
      "6480/6480 [==============================] - 66s - loss: 1.1921e-07 - acc: 0.5877 - val_loss: 1.1921e-07 - val_acc: 0.6046\n",
      "Epoch 265/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 1.1921e-07 - acc: 0.5874Epoch 00264: val_acc did not improve\n",
      "6480/6480 [==============================] - 66s - loss: 1.1921e-07 - acc: 0.5877 - val_loss: 1.1921e-07 - val_acc: 0.6046\n",
      "Epoch 266/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 1.1921e-07 - acc: 0.5871Epoch 00265: val_acc did not improve\n",
      "6480/6480 [==============================] - 66s - loss: 1.1921e-07 - acc: 0.5877 - val_loss: 1.1921e-07 - val_acc: 0.6046\n",
      "Epoch 267/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 1.1921e-07 - acc: 0.5880Epoch 00266: val_acc did not improve\n",
      "6480/6480 [==============================] - 66s - loss: 1.1921e-07 - acc: 0.5877 - val_loss: 1.1921e-07 - val_acc: 0.6046\n",
      "Epoch 268/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 1.1921e-07 - acc: 0.5880Epoch 00267: val_acc did not improve\n",
      "6480/6480 [==============================] - 66s - loss: 1.1921e-07 - acc: 0.5877 - val_loss: 1.1921e-07 - val_acc: 0.6046\n",
      "Epoch 269/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 1.1921e-07 - acc: 0.5876Epoch 00268: val_acc did not improve\n",
      "6480/6480 [==============================] - 66s - loss: 1.1921e-07 - acc: 0.5877 - val_loss: 1.1921e-07 - val_acc: 0.6046\n",
      "Epoch 270/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 1.1921e-07 - acc: 0.5877Epoch 00269: val_acc did not improve\n",
      "6480/6480 [==============================] - 66s - loss: 1.1921e-07 - acc: 0.5877 - val_loss: 1.1921e-07 - val_acc: 0.6046\n",
      "Epoch 271/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 1.1921e-07 - acc: 0.5885Epoch 00270: val_acc did not improve\n",
      "6480/6480 [==============================] - 66s - loss: 1.1921e-07 - acc: 0.5877 - val_loss: 1.1921e-07 - val_acc: 0.6046\n",
      "Epoch 272/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 1.1921e-07 - acc: 0.5883Epoch 00271: val_acc did not improve\n",
      "6480/6480 [==============================] - 64s - loss: 1.1921e-07 - acc: 0.5877 - val_loss: 1.1921e-07 - val_acc: 0.6046\n",
      "Epoch 273/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 1.1921e-07 - acc: 0.5873Epoch 00272: val_acc did not improve\n",
      "6480/6480 [==============================] - 65s - loss: 1.1921e-07 - acc: 0.5877 - val_loss: 1.1921e-07 - val_acc: 0.6046\n",
      "Epoch 274/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 1.1921e-07 - acc: 0.5877Epoch 00273: val_acc did not improve\n",
      "6480/6480 [==============================] - 65s - loss: 1.1921e-07 - acc: 0.5877 - val_loss: 1.1921e-07 - val_acc: 0.6046\n",
      "Epoch 275/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 1.1921e-07 - acc: 0.5877Epoch 00274: val_acc did not improve\n",
      "6480/6480 [==============================] - 66s - loss: 1.1921e-07 - acc: 0.5877 - val_loss: 1.1921e-07 - val_acc: 0.6046\n",
      "Epoch 276/3000\n",
      "3168/6480 [=============>................] - ETA: 33s - loss: 1.1921e-07 - acc: 0.5833"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-128-65100d1ab8aa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m# Fit the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_1Hot_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[0;32m    861\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    862\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 863\u001b[1;33m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m    864\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    865\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[0;32m   1428\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1429\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1430\u001b[1;33m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1431\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1432\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[0;32m   1077\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'size'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1078\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1079\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1080\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1081\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2266\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[0;32m   2267\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2268\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2269\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2270\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    765\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 767\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    768\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    963\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m--> 965\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    966\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1013\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m-> 1015\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m   1016\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1020\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1021\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1022\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1023\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[0;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1004\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m   1005\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1006\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "##### from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "# serialize model to YAML\n",
    "model_yaml = model.to_yaml()\n",
    "with open(\"model_v8v3_layer_cnn.yaml\", \"w\") as yaml_file:\n",
    "    yaml_file.write(model_yaml)\n",
    "# checkpoint\n",
    "filepath=\"weights.bestv8v3.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "early_stopping = EarlyStopping(monitor='val_acc', patience=150)\n",
    "callbacks_list = [checkpoint, early_stopping]\n",
    "\n",
    "# Fit the model\n",
    "history = model.fit(X_train, y_1Hot_train, epochs=3000, validation_split=0.2 , callbacks=callbacks_list, shuffle=True, batch_size=32)\n",
    "\n",
    "\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"weights_v8v3_layer_cnn.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6480 samples, validate on 1621 samples\n",
      "Epoch 1/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.8984 - acc: 0.6188Epoch 00000: val_acc improved from -inf to 0.05305, saving model to weights.bestv8v3.hdf5\n",
      "6480/6480 [==============================] - 69s - loss: 0.8985 - acc: 0.6188 - val_loss: 1.6439 - val_acc: 0.0531\n",
      "Epoch 2/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.7571 - acc: 0.6821Epoch 00001: val_acc improved from 0.05305 to 0.59593, saving model to weights.bestv8v3.hdf5\n",
      "6480/6480 [==============================] - 23s - loss: 0.7571 - acc: 0.6823 - val_loss: 0.9341 - val_acc: 0.5959\n",
      "Epoch 3/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.6969 - acc: 0.7079Epoch 00002: val_acc improved from 0.59593 to 0.71993, saving model to weights.bestv8v3.hdf5\n",
      "6480/6480 [==============================] - 23s - loss: 0.6971 - acc: 0.7077 - val_loss: 0.6718 - val_acc: 0.7199\n",
      "Epoch 4/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.6447 - acc: 0.7308Epoch 00003: val_acc did not improve\n",
      "6480/6480 [==============================] - 23s - loss: 0.6439 - acc: 0.7312 - val_loss: 0.7257 - val_acc: 0.7008\n",
      "Epoch 5/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.6377 - acc: 0.7347Epoch 00004: val_acc improved from 0.71993 to 0.73967, saving model to weights.bestv8v3.hdf5\n",
      "6480/6480 [==============================] - 23s - loss: 0.6366 - acc: 0.7352 - val_loss: 0.6676 - val_acc: 0.7397\n",
      "Epoch 6/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.6172 - acc: 0.7418Epoch 00005: val_acc did not improve\n",
      "6480/6480 [==============================] - 23s - loss: 0.6167 - acc: 0.7421 - val_loss: 0.9289 - val_acc: 0.6157\n",
      "Epoch 7/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.5816 - acc: 0.7580Epoch 00006: val_acc improved from 0.73967 to 0.75262, saving model to weights.bestv8v3.hdf5\n",
      "6480/6480 [==============================] - 23s - loss: 0.5821 - acc: 0.7574 - val_loss: 0.6999 - val_acc: 0.7526\n",
      "Epoch 8/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.5568 - acc: 0.7743Epoch 00007: val_acc did not improve\n",
      "6480/6480 [==============================] - 23s - loss: 0.5565 - acc: 0.7742 - val_loss: 0.5983 - val_acc: 0.7489\n",
      "Epoch 9/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.5477 - acc: 0.7724Epoch 00008: val_acc improved from 0.75262 to 0.76373, saving model to weights.bestv8v3.hdf5\n",
      "6480/6480 [==============================] - 23s - loss: 0.5480 - acc: 0.7724 - val_loss: 0.7088 - val_acc: 0.7637\n",
      "Epoch 10/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.5299 - acc: 0.7799Epoch 00009: val_acc did not improve\n",
      "6480/6480 [==============================] - 23s - loss: 0.5307 - acc: 0.7796 - val_loss: 0.7425 - val_acc: 0.7569\n",
      "Epoch 11/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.5150 - acc: 0.7916Epoch 00010: val_acc improved from 0.76373 to 0.78532, saving model to weights.bestv8v3.hdf5\n",
      "6480/6480 [==============================] - 23s - loss: 0.5150 - acc: 0.7912 - val_loss: 0.5712 - val_acc: 0.7853\n",
      "Epoch 12/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.4893 - acc: 0.8068Epoch 00011: val_acc did not improve\n",
      "6480/6480 [==============================] - 23s - loss: 0.4903 - acc: 0.8063 - val_loss: 0.6703 - val_acc: 0.7785\n",
      "Epoch 13/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.4833 - acc: 0.8136Epoch 00012: val_acc improved from 0.78532 to 0.80814, saving model to weights.bestv8v3.hdf5\n",
      "6480/6480 [==============================] - 23s - loss: 0.4832 - acc: 0.8136 - val_loss: 0.5232 - val_acc: 0.8081\n",
      "Epoch 14/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.4608 - acc: 0.8205Epoch 00013: val_acc did not improve\n",
      "6480/6480 [==============================] - 23s - loss: 0.4627 - acc: 0.8202 - val_loss: 1.2005 - val_acc: 0.4849\n",
      "Epoch 15/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.4651 - acc: 0.8233Epoch 00014: val_acc did not improve\n",
      "6480/6480 [==============================] - 23s - loss: 0.4655 - acc: 0.8230 - val_loss: 0.5967 - val_acc: 0.7409\n",
      "Epoch 16/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.4605 - acc: 0.8235Epoch 00015: val_acc did not improve\n",
      "6480/6480 [==============================] - 23s - loss: 0.4603 - acc: 0.8235 - val_loss: 0.5243 - val_acc: 0.8014\n",
      "Epoch 17/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.4465 - acc: 0.8292Epoch 00016: val_acc improved from 0.80814 to 0.80938, saving model to weights.bestv8v3.hdf5\n",
      "6480/6480 [==============================] - 23s - loss: 0.4468 - acc: 0.8292 - val_loss: 0.4767 - val_acc: 0.8094\n",
      "Epoch 18/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.4236 - acc: 0.8413Epoch 00017: val_acc did not improve\n",
      "6480/6480 [==============================] - 23s - loss: 0.4229 - acc: 0.8415 - val_loss: 0.8244 - val_acc: 0.6737\n",
      "Epoch 19/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.4156 - acc: 0.8444Epoch 00018: val_acc did not improve\n",
      "6480/6480 [==============================] - 23s - loss: 0.4151 - acc: 0.8448 - val_loss: 0.5973 - val_acc: 0.7977\n",
      "Epoch 20/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.4043 - acc: 0.8485Epoch 00019: val_acc improved from 0.80938 to 0.81616, saving model to weights.bestv8v3.hdf5\n",
      "6480/6480 [==============================] - 23s - loss: 0.4036 - acc: 0.8489 - val_loss: 0.5200 - val_acc: 0.8162\n",
      "Epoch 21/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.3979 - acc: 0.8485Epoch 00020: val_acc did not improve\n",
      "6480/6480 [==============================] - 23s - loss: 0.3979 - acc: 0.8488 - val_loss: 0.5599 - val_acc: 0.7903\n",
      "Epoch 22/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.3891 - acc: 0.8465Epoch 00021: val_acc did not improve\n",
      "6480/6480 [==============================] - 23s - loss: 0.3897 - acc: 0.8460 - val_loss: 0.7621 - val_acc: 0.7742\n",
      "Epoch 23/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.3905 - acc: 0.8498Epoch 00022: val_acc did not improve\n",
      "6480/6480 [==============================] - 23s - loss: 0.3915 - acc: 0.8492 - val_loss: 0.4989 - val_acc: 0.8137\n",
      "Epoch 24/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.3785 - acc: 0.8595Epoch 00023: val_acc did not improve\n",
      "6480/6480 [==============================] - 23s - loss: 0.3795 - acc: 0.8591 - val_loss: 0.4882 - val_acc: 0.8094\n",
      "Epoch 25/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.3746 - acc: 0.8597Epoch 00024: val_acc did not improve\n",
      "6480/6480 [==============================] - 23s - loss: 0.3748 - acc: 0.8594 - val_loss: 0.5164 - val_acc: 0.8149\n",
      "Epoch 26/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.3706 - acc: 0.8654Epoch 00025: val_acc improved from 0.81616 to 0.82357, saving model to weights.bestv8v3.hdf5\n",
      "6480/6480 [==============================] - 23s - loss: 0.3711 - acc: 0.8650 - val_loss: 0.5117 - val_acc: 0.8236\n",
      "Epoch 27/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.3563 - acc: 0.8693Epoch 00026: val_acc did not improve\n",
      "6480/6480 [==============================] - 23s - loss: 0.3559 - acc: 0.8694 - val_loss: 0.5173 - val_acc: 0.7940\n",
      "Epoch 28/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.3461 - acc: 0.8700Epoch 00027: val_acc improved from 0.82357 to 0.82665, saving model to weights.bestv8v3.hdf5\n",
      "6480/6480 [==============================] - 23s - loss: 0.3465 - acc: 0.8698 - val_loss: 0.5121 - val_acc: 0.8267\n",
      "Epoch 29/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.3584 - acc: 0.8646Epoch 00028: val_acc improved from 0.82665 to 0.83220, saving model to weights.bestv8v3.hdf5\n",
      "6480/6480 [==============================] - 23s - loss: 0.3579 - acc: 0.8648 - val_loss: 0.5044 - val_acc: 0.8322\n",
      "Epoch 30/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.3387 - acc: 0.8727Epoch 00029: val_acc did not improve\n",
      "6480/6480 [==============================] - 23s - loss: 0.3394 - acc: 0.8722 - val_loss: 0.4873 - val_acc: 0.8180\n",
      "Epoch 31/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.3294 - acc: 0.8795Epoch 00030: val_acc did not improve\n",
      "6480/6480 [==============================] - 23s - loss: 0.3292 - acc: 0.8795 - val_loss: 0.5623 - val_acc: 0.8186\n",
      "Epoch 32/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.3243 - acc: 0.8782Epoch 00031: val_acc improved from 0.83220 to 0.84146, saving model to weights.bestv8v3.hdf5\n",
      "6480/6480 [==============================] - 23s - loss: 0.3251 - acc: 0.8781 - val_loss: 0.4362 - val_acc: 0.8415\n",
      "Epoch 33/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.3153 - acc: 0.8807Epoch 00032: val_acc did not improve\n",
      "6480/6480 [==============================] - 23s - loss: 0.3153 - acc: 0.8807 - val_loss: 0.4987 - val_acc: 0.8304\n",
      "Epoch 34/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.3075 - acc: 0.8858Epoch 00033: val_acc did not improve\n",
      "6480/6480 [==============================] - 23s - loss: 0.3074 - acc: 0.8860 - val_loss: 0.5044 - val_acc: 0.8260\n",
      "Epoch 35/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.3051 - acc: 0.8878Epoch 00034: val_acc did not improve\n",
      "6480/6480 [==============================] - 23s - loss: 0.3055 - acc: 0.8877 - val_loss: 0.5700 - val_acc: 0.7946\n",
      "Epoch 36/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.3086 - acc: 0.8855Epoch 00035: val_acc did not improve\n",
      "6480/6480 [==============================] - 23s - loss: 0.3083 - acc: 0.8855 - val_loss: 0.5051 - val_acc: 0.8341\n",
      "Epoch 37/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.2957 - acc: 0.8934Epoch 00036: val_acc did not improve\n",
      "6480/6480 [==============================] - 23s - loss: 0.2962 - acc: 0.8934 - val_loss: 0.5405 - val_acc: 0.8192\n",
      "Epoch 38/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.2874 - acc: 0.8937Epoch 00037: val_acc did not improve\n",
      "6480/6480 [==============================] - 23s - loss: 0.2882 - acc: 0.8934 - val_loss: 0.5576 - val_acc: 0.7995\n",
      "Epoch 39/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.2888 - acc: 0.8990Epoch 00038: val_acc did not improve\n",
      "6480/6480 [==============================] - 23s - loss: 0.2888 - acc: 0.8991 - val_loss: 0.5254 - val_acc: 0.8322\n",
      "Epoch 40/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.2800 - acc: 0.8976Epoch 00039: val_acc did not improve\n",
      "6480/6480 [==============================] - 23s - loss: 0.2796 - acc: 0.8977 - val_loss: 0.6009 - val_acc: 0.8100\n",
      "Epoch 41/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.2647 - acc: 0.9033Epoch 00040: val_acc did not improve\n",
      "6480/6480 [==============================] - 23s - loss: 0.2655 - acc: 0.9026 - val_loss: 0.4767 - val_acc: 0.8353\n",
      "Epoch 42/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.2709 - acc: 0.8994Epoch 00041: val_acc did not improve\n",
      "6480/6480 [==============================] - 23s - loss: 0.2707 - acc: 0.8995 - val_loss: 0.6270 - val_acc: 0.8044\n",
      "Epoch 43/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.2699 - acc: 0.9045Epoch 00042: val_acc did not improve\n",
      "6480/6480 [==============================] - 23s - loss: 0.2704 - acc: 0.9043 - val_loss: 0.4985 - val_acc: 0.8267\n",
      "Epoch 44/3000\n",
      "6464/6480 [============================>.] - ETA: 0s - loss: 0.2601 - acc: 0.9045Epoch 00043: val_acc did not improve\n",
      "6480/6480 [==============================] - 23s - loss: 0.2603 - acc: 0.9043 - val_loss: 0.5770 - val_acc: 0.8378\n",
      "Epoch 45/3000\n",
      "2304/6480 [=========>....................] - ETA: 14s - loss: 0.2478 - acc: 0.9071"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-117-7a8ec910db00>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m# Fit the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_1Hot_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[0;32m    861\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    862\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 863\u001b[1;33m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m    864\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    865\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[0;32m   1428\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1429\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1430\u001b[1;33m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1431\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1432\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[0;32m   1077\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'size'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1078\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1079\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1080\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1081\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2266\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[0;32m   2267\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2268\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2269\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2270\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    765\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 767\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    768\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    963\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m--> 965\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    966\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1013\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m-> 1015\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m   1016\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1020\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1021\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1022\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1023\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[0;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1004\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m   1005\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1006\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "##### from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "# serialize model to YAML\n",
    "model_yaml = model.to_yaml()\n",
    "with open(\"model_v8v3_layer_cnn.yaml\", \"w\") as yaml_file:\n",
    "    yaml_file.write(model_yaml)\n",
    "# checkpoint\n",
    "filepath=\"weights.bestv8v3.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "early_stopping = EarlyStopping(monitor='val_acc', patience=150)\n",
    "callbacks_list = [checkpoint, early_stopping]\n",
    "\n",
    "# Fit the model\n",
    "history = model.fit(X_train, y_1Hot_train, epochs=3000, validation_split=0.2 , callbacks=callbacks_list, shuffle=True, batch_size=64)\n",
    "\n",
    "\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"weights_v8v3_layer_cnn.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Conv1D, GlobalAveragePooling1D, MaxPooling1D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers import LSTM\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv1D(64, 5,  init='uniform', input_shape=X_train.shape[1:3]))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Conv1D(64, 5,  init='uniform'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Conv1D(64, 5,  init='uniform'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Conv1D(64, 5,  init='uniform'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Conv1D(128, 5,  init='uniform'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Conv1D(128, 5,  init='uniform'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Conv1D(128, 5,  init='uniform'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Conv1D(128, 5,  init='uniform'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Conv1D(256, 5,  init='uniform'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Conv1D(256, 5,  init='uniform'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Conv1D(256, 5,  init='uniform'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Conv1D(256, 5,  init='uniform'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "#model.add(GlobalAveragePooling1D())\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "model.add(LSTM(256, dropout=0.2, recurrent_dropout=0.2))\n",
    "\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "# # Compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n",
      "acc: 86.65%\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.96      0.89       262\n",
      "          1       0.94      0.87      0.90        38\n",
      "          2       0.86      0.64      0.73       116\n",
      "          3       1.00      0.55      0.71        11\n",
      "\n",
      "avg / total       0.86      0.85      0.85       427\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1wAAANqCAYAAACZxkp0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x20d91ac6c88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load weights into new model\n",
    "model.load_weights(\"C:\\jupyter\\weights.bestv8v3.hdf5\")\n",
    "print(\"Loaded model from disk\")\n",
    " \n",
    "# evaluate loaded model on test data\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "score = model.evaluate(X_test, y_1Hot_test, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], score[1]*100))\n",
    "\n",
    "y_true, y_pred = y_1Hot_test.astype('int'), model.predict(X_test)\n",
    "y_pred = y_pred.round().astype('int')\n",
    "\n",
    "# from categorial to lable indexing\n",
    "y_pred = y_pred.argmax(1)\n",
    "y_true = y_true.argmax(1)\n",
    "\n",
    "print(classification_report(y_true, y_pred))\n",
    "plot_confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n",
      "acc: 86.89%\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.96      0.92       262\n",
      "          1       0.87      0.87      0.87        38\n",
      "          2       0.84      0.70      0.76       116\n",
      "          3       0.80      0.36      0.50        11\n",
      "\n",
      "avg / total       0.86      0.87      0.86       427\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1wAAANqCAYAAACZxkp0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRHABAABMIrgAAAAm+R/imBEH6jrcsgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x20b4cc32d30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load weights into new model\n",
    "model.load_weights(\"C:\\jupyter\\weights.bestv8v1.hdf5\")\n",
    "print(\"Loaded model from disk\")\n",
    " \n",
    "# evaluate loaded model on test data\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "score = model.evaluate(X_test, y_1Hot_test, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], score[1]*100))\n",
    "\n",
    "y_true, y_pred = y_1Hot_test.astype('int'), model.predict(X_test)\n",
    "y_pred = y_pred.round().astype('int')\n",
    "\n",
    "# from categorial to lable indexing\n",
    "y_pred = y_pred.argmax(1)\n",
    "y_true = y_true.argmax(1)\n",
    "\n",
    "print(classification_report(y_true, y_pred))\n",
    "plot_confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##### from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "# serialize model to YAML\n",
    "model_yaml = model.to_yaml()\n",
    "with open(\"model_v6v11_layer_cnn.yaml\", \"w\") as yaml_file:\n",
    "    yaml_file.write(model_yaml)\n",
    "# checkpoint\n",
    "filepath=\"weights.bestv6v11b.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "early_stopping = EarlyStopping(monitor='val_acc', patience=150)\n",
    "callbacks_list = [checkpoint, early_stopping]\n",
    "\n",
    "# Fit the model\n",
    "history = model.fit(X_train, y_1Hot_train, epochs=3000, validation_split=0.1 , callbacks=callbacks_list, shuffle=True, batch_size=18)\n",
    "\n",
    "\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"weights_v6v11_layer_cnn.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "# serialize model to YAML\n",
    "model_yaml = model.to_yaml()\n",
    "with open(\"model_v6v10_layer_cnn.yaml\", \"w\") as yaml_file:\n",
    "    yaml_file.write(model_yaml)\n",
    "# checkpoint\n",
    "filepath=\"weights.bestv6v10.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "early_stopping = EarlyStopping(monitor='val_acc', patience=150)\n",
    "callbacks_list = [checkpoint, early_stopping]\n",
    "\n",
    "# Fit the model\n",
    "history = model.fit(X_train, y_1Hot_train, epochs=3000, validation_split=0.15 , callbacks=callbacks_list, shuffle=True, batch_size=18)\n",
    "\n",
    "\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"weights_v6v10_layer_cnn.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# serialize model to YAML\n",
    "model_yaml = model.to_yaml()\n",
    "with open(\"model_v6v11_layer_cnn.yaml\", \"w\") as yaml_file:\n",
    "    yaml_file.write(model_yaml)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"weights_v6v10_layer_cnn.h5\")\n",
    "print(\"Saved model to disk\")\n",
    "\n",
    "# load weights into new model\n",
    "model.load_weights(\"C:\\jupyter\\weights.bestv6v11.hdf5\")\n",
    "print(\"Loaded model from disk\")\n",
    " \n",
    "# evaluate loaded model on test data\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "score = model.evaluate(X_test, y_1Hot_test, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], score[1]*100))\n",
    "\n",
    "y_true, y_pred = y_1Hot_test.astype('int'), model.predict(X_test)\n",
    "y_pred = y_pred.round().astype('int')\n",
    "\n",
    "# from categorial to lable indexing\n",
    "y_pred = y_pred.argmax(1)\n",
    "y_true = y_true.argmax(1)\n",
    "\n",
    "print(classification_report(y_true, y_pred))\n",
    "plot_confusion_matrix(y_true, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n",
      "acc: 86.42%\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.95      0.92       262\n",
      "          1       0.89      0.87      0.88        38\n",
      "          2       0.82      0.72      0.77       116\n",
      "          3       0.75      0.55      0.63        11\n",
      "\n",
      "avg / total       0.87      0.87      0.87       427\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1wAAANqCAYAAACZxkp0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nACb5HzqkB7ps3336AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x20b288cff60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load weights into new model\n",
    "model.load_weights(\"C:\\jupyter\\weights.bestv6v9.hdf5\")\n",
    "print(\"Loaded model from disk\")\n",
    " \n",
    "# evaluate loaded model on test data\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "score = model.evaluate(X_test, y_1Hot_test, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], score[1]*100))\n",
    "\n",
    "y_true, y_pred = y_1Hot_test.astype('int'), model.predict(X_test)\n",
    "y_pred = y_pred.round().astype('int')\n",
    "\n",
    "# from categorial to lable indexing\n",
    "y_pred = y_pred.argmax(1)\n",
    "y_true = y_true.argmax(1)\n",
    "\n",
    "print(classification_report(y_true, y_pred))\n",
    "plot_confusion_matrix(y_true, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n",
      "acc: 88.06%\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.95      0.92       262\n",
      "          1       0.92      0.89      0.91        38\n",
      "          2       0.86      0.73      0.79       116\n",
      "          3       0.71      0.45      0.56        11\n",
      "\n",
      "avg / total       0.87      0.88      0.87       427\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1wAAANqCAYAAACZxkp0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x209cee53940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load weights into new model\n",
    "model.load_weights(\"C:\\jupyter\\weights.bestv6v6.hdf5\")\n",
    "print(\"Loaded model from disk\")\n",
    " \n",
    "# evaluate loaded model on test data\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "score = model.evaluate(X_test, y_1Hot_test, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], score[1]*100))\n",
    "\n",
    "y_true, y_pred = y_1Hot_test.astype('int'), model.predict(X_test)\n",
    "y_pred = y_pred.round().astype('int')\n",
    "\n",
    "# from categorial to lable indexing\n",
    "y_pred = y_pred.argmax(1)\n",
    "y_true = y_true.argmax(1)\n",
    "\n",
    "print(classification_report(y_true, y_pred))\n",
    "plot_confusion_matrix(y_true, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n",
      "acc: 86.64%\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.97      0.92      1003\n",
      "          1       0.83      0.80      0.81       162\n",
      "          2       0.86      0.71      0.78       486\n",
      "          3       0.84      0.49      0.62        55\n",
      "\n",
      "avg / total       0.86      0.86      0.86      1706\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARwAAAEqCAYAAADH1+9QAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xl8FPX9x/HXBwJ4FFQqSgiHCppAuBIIUUK9ERREixxi\nRS2i0kpFbatY1Kr1QFAsild/1apYRdFW5BC8QUFORUQURQEh8RbLTQ6+vz9mEkMIYZHNd8Lm/Xw8\n9pHMd2ZnPrPZfec735ndNeccIiI+1Ii6ABGpPhQ4IuKNAkdEvFHgiIg3ChwR8UaBIyLeKHA8MbPj\nzOxZM8szs3wz+97MXjGzC8ysZiVu90wz+8DMtpqZM7OD47juE8N1nhivdVYVZnaEmd1kZkft4X2c\nmV1UiaXt0xQ4HpjZlcBsoD5wLXAqMAj4BHgI6FlJ200C/g3kAqcBxwEb4riJd8N1vhvHdVYVRwB/\nBWIOHOBLgsdjamUUlAiSoi4g0ZnZ8cAYYJxz7ooysyeZ2d3ALypp8ylAXeBZ59yseK/cObcemBvv\n9e5rzMyAWs65bejxqJhzTrdKvBH8t/sO2C/G5TsBrwIbgU3Aa0CnMss8BqwFMoC3gM3Ap8CQUsvc\nBLgytzfDeauAx8rZtgNuKjV9DPBf4BtgK/AFMBFICuefGN7nxFL3MeAqYDmQT/BffxxQr5xt3Qpc\nAawk6HnNBNJjeIyK978jMAfYEm6vRzj/6nAf1wOTgAZl7j8UeAf4AfiRICR6lJpfvF9lbyeWevye\nJOilfgwUAL8m6BU54KJwuYbhY/ffMtu/JFyuZ9TPT++vh6gLSOQbUDMMg6diXL5t+OJZBPQBzgEW\nhG3tSi33WPhi+gi4DOgKPBU+iU8Kl2kcrsMBfwOOBVqF82INnE+B+WEdJwDnhS+02uH88gLn9rBt\nHNAtDJ+NBMFYo8y2VgEzgF5hrSuBFYSBVsHjVLz/y8IXffdw/VuBu4HJQI9w3nqCHl7p+98dPm6n\nhjWOC+vpHs6vB/w+bPtD+NgdSxiaYd25wFJgAHAK0Lxs4ITL9gjbhoTTLQn+kdwb9fMzktdE1AUk\n8g04PHyy3RHj8s8R/Mc9uFRbPYL/xP8p1fZY6XAJ2+oA3wP/KNXWouwLIGzfbeAAh4bTvSqod4fA\nIRij2lZ23cD5ZdcVTn9KcChS3FYckJ138zgV7//xpdrahm3LgZql2scQ9EBq7mJdNQiGFl4GJpWz\nb6eWc59VBP9IGpZp3ylwwvax4fKZwPvhrU7Uz88obho0rlqOB6Y4534sbnDBOMmLBD2M0jY7594o\ntdw2gkHopnGq5Xvgc2CkmV1iZkfHcJ9jgdoEvaDSJgCF7LwPrzjnCkpNfxD+jGUfNrkdx6U+Dn++\n6pwrKtOeBCQXN5hZBzObYmZfh3UVEPQSU2PYbrG5zrmvYlz2GoK/zRzgaGBA+PeqdhQ4let7gsOh\nZjEuX59gzKOsr4BDyrStK2e5bcB+MVdXARf8a+4KLATuAD4xs8/N7HcV3K1++HOHfXDOFRI8FvXL\nLP9DmeniF2Es+/Bj6QnnXH74a9nHpbh9PwAza0IwLlaf4HCpM5AFTI9xu8XK+zuVKwyXZwh6oS87\n55btwXYSigKnEoUvtDeBrmZWJ4a7/EAw0FhWQ8oPmJ9rK0FPpISZ/bLsQs65z51zFwANCAaoXwce\nMLPTd7He4gDZYR/C0/O/ZOeAiUJ34CCgn3PuWefcXOfcQuCAPVxPzJ/rYmbpwA0E4X2WmZ21h9tK\nGAqcyjeS4MU2qryZZnakmbUNJ2cCZ5hZ3VLz6wJnEgRXvKwGWpdp67GrhV1gMcHZH8q5b7G5BD2K\nc8u09yc4rHlzjyuNv+JgKTmUM7NjgJwyyxX3tvbfm42Z2X7A0wSHdjnAf4BHzKzR3qx3X6XrcCqZ\nc26WmV0NjDGzVgQDnl8QHCKdAgwmOPuzhOBsUk/gNTO7k+C/6LUEL5Jb4ljWBOBRM7sHmAK0Ay4q\nvUAYgmMJDgVWEJxxu4hgzOP18lbqnPshvK7oOjPbBEwjOCtzK/A2VeOCuFcJ9uGJsNZk4GaCv0np\nf8CfhMsNMrMfCAJouXNuTy+cHE1wBivTOZdvZpcQDBo/YWZdw0PXakM9HA+cc38HuhCMO9xF8IJ9\njODFeBnBaVycc0sIzo6sBx4HxhOcUj7BOfd+HEt6nOAq2t7htrsRXEdS2lcEL8KrCQatnwYaEVw7\nsqiCdY8I73M6QZgNB54guM5lexz34Wdxzn0I/IZgXO1FggHd4cCsMst9T3C9TjuCnucCoMOebMvM\neobrGOacWx6u9weCs3YnhduuVqyaBayIREg9HBHxRoEjIt4ocETEGwWOiHhTpU+LW9L+zmrX3f2C\nCSCjZbzekVD1RX6qyqPq8h999epVfPfdd7a75ap24NSuS53UflGX4cXseeOiLsGb/MLqEzm1k6pH\n5ORkd4xpuerxaIhIlaDAERFvFDgi4o0CR0S8UeCIiDcKHBHxRoEjIt4ocETEGwWOiHijwBERbxQ4\nIuKNAkdEvFHgiIg3ChwR8UaBIyLeKHBExBsFjoh4o8AREW8UOCLijQJHRLxR4IiIN9UucC4fcCIL\nJ/6FRc+NYOh5JwIwfuRvmTthOHMnDOfjqTczd8JwADqmNytpn/fMcHqd1DbCyuNjzZo1dDv1JDLa\ntiKzXTrj7h0bdUlxtXbNGnp2O4VOGa3JzmzDg+PuBWDJ+4s55fjOdMnO5IScTixaMD/iSuPv5RnT\naZueSnpaC0aPGhl1OeWq0l8TE2+tmifz296d+dXA0eQXFPHi/b9n2ltLGTj8XyXLjLz61/xv4xYA\nPvwsj5zfjKKoaDsND63HvGeuY+qspRQV7btfc5KUlMTIUXeTkZnJhg0b6JzdgVNO7UrLVq2iLi0u\nkpKSuHXkaNpnBPt3QucsTjrlVG4ccS3DR9xA126n8/L0adw4YjhTX3496nLjpqioiCuvuJypL71C\nSuPGdDk2i549e1W5v2u16uGkHdmQBUtXsWVrAUVF23lr0QrOPrn9Dsuc0zWTZ6cvAihZDqBO7Vo4\n57zXHG/JyclkZGYCULduXdLSWpKXlxtxVfHTMDmZ9hk/7V9qWhp5ebmYGevXrwdg/f/+R8Pk5CjL\njLsF8+fTvHkLjjzqKGrXrk3f/ucyZfKkqMvaSbXq4Xz4WR43DT2T+gcdyJZt+XTvks67y74omZ+T\n2Zyvf9jAZ198W9KW1boZD910Pk2T63Px9Y/v072bslavWsXixe+R1Sk76lIqxerVq1iyeDEds7IZ\nOfoeep95Ojdcdw3bt2/n5Tfejrq8uMrLy6Vx4yYl0ykpjZk/f16EFZXPaw/HzLqb2XIzW2Fmw31u\nG2D5yq+5+7FXmPzA5bx4/+W8v3ztDgHSr3tHJk5fuMN9FixdTYc+t9Hl/FH8edBp1KmdGBm9ceNG\nBvQ7h9F3/5169epFXU7cbdy4kYED+nLH6DHUq1ePR/7xELePuptlK1Zz+6i7Gfq7S6IusVryFjhm\nVhO4HzgdaAUMMDPvB5iPv/AOOb8ZRdeL/86P6zfz6epvAKhZswZnndyO52a8W+79lq/8mo2bt5He\nopHPcitFQUEBA/qdQ/8Bv+HsX/eOupy4KygoYOCAPvTrfx69zg727+l/P1Hy+6/P6cu7CxNr0LhR\noxTWrl1TMp2bu5aUlJQIKyqfzx5OJ2CFc+5z51w+MAE4y+P2AWhwyC8AaNLwEM46uR3PvBT0aE7O\nTuWTVV+T+82PJcs2a/RLatYMHqKmyYeQemRDVud977vkuHLOMeSSi0lNa8mwq66Oupy4c84xdMhg\nUlNbMnTYVSXtDZMb8fZbMwGY+ebrHNXi6KhKrBQds7JYseJTVq1cSX5+PhOfmUCPnr2iLmsnPo8P\nUoA1pabXAjsNHpjZpcClANT6RdyLePquwdQ/+EAKCou4cuSzJWek+nbrUDJYXKxzxlH86benUVBY\nxPbtjmG3P8P3P26Ke00+zZk9m6f+PZ7WrduQ3SEYML/51tvpfvoZEVcWH3PnzGbCU0+S3roNXbKD\nweMbb76Ve+9/mGv/fBVFhYXUqbMfY8c9FHGl8ZWUlMQ9Y8dxZo9uFBUVceFFg2iVnh51WTsxX2de\nzKwP0N05NzicHghkO+eG7uo+NQ44zNVJ7eelvqitWzAu6hK8yS9MnIH33amdVD1OBOdkd2TRooW2\nu+V8Phq5QJNS043DNhGpJnwGzgLgaDM70sxqA+cCL3rcvohEzNsYjnOu0MyGAjOAmsCjzrkPfW1f\nRKLn9aIS59w0YJrPbYpI1VE9RrREpEpQ4IiINwocEfFGgSMi3ihwRMQbBY6IeKPAERFvFDgi4o0C\nR0S8UeCIiDcKHBHxRoEjIt4ocETEGwWOiHijwBERbxQ4IuKNAkdEvFHgiIg3ChwR8UaBIyLeKHBE\nxBsFjoh44/VrYvZU+5ZNefud+6Iuw4u8dVuiLsGbBnXrRF2CREQ9HBHxRoEjIt4ocETEGwWOiHij\nwBERbxQ4IuKNAkdEvFHgiIg3ChwR8UaBIyLeKHBExBsFjoh4o8AREW8UOCLijQJHRLxR4IiINwoc\nEfFGgSMi3ihwRMQbBY6IeKPAERFvFDgi4o0CJ3Tf2Hvo2L41HTPacOHA89i6dWvUJe2Va4ddRlar\nZnQ/vmNJ2x03/YWundtzxgmdGHJhf9b/70cA8vPzueaKSzn9hCx6nJjN3Nmzoip7r61ds4Ye3U4h\nK6M1nTLb8MC4ewG4/dabST2qCTnZmeRkZzJj+rSIK42/l2dMp216KulpLRg9amTU5ZRLgQPk5eby\n4P338dY7C1j43gdsLypi4rMToi5rr5xz7kD+NeGFHdq6nHAyL81ayLSZ8zmy+dE8OPYuAJ4Z/ygA\nL81cwOMTJ3P7X4ezfft27zXHQ1JSEreNHM2C95by2sw5/N/DD/DxR8sAuPwPVzJ73rvMnvcu3bqf\nEXGl8VVUVMSVV1zOpMkv8d6SZUyc8DQfLVsWdVk7UeCECosK2bJlC4WFhWzevJnk5EZRl7RXOh3X\nhYMPrr9D269OOpWkpOC7D9t3yOKrvFwAVnzyMcd1ORGAQxscRr2DDuaDxYu81hsvDZOTaZ+RCUDd\nunVJTUsjL9zPRLZg/nyaN2/BkUcdRe3atenb/1ymTJ4UdVk7UeAAjVJSGHblH0lr0YzmzRpR76CD\nOLXraVGXVamee/oJTjgl2Me09Da8NmMqhYWFrFm9iqXvv8eXufv+i3T16lUsWbyYjlnZADz84DiO\ny2rP7y+7mHXr1kVcXXzl5eXSuHGTkumUlMbkVsG/4S4Dx8zOiPUWy4bM7FEz+8bMlsav/PhYt24d\nU6a8yIfLP2fFqlw2b9rE0089GXVZleb+e+6kZs0kzupzLgB9z7uQho1SOLtrDrfe8Gcys7KpUXPf\n/l+0ceNGBg7oy8jRY6hXrx6DLxnCko9WMHveuzRsmMyI4X+KusRqqaLvFp8S4zocUDOG5R4DxgFP\nxLheb954/VWOOOIIGjRoAECvs3/NvHfmMOC88yOuLP6emzCeN15+ifHPT8PMgGDc4/q/jSpZps8Z\nJ3Fk86OjKnGvFRQUcP6APvTrfx69zu4NwGGHH14y/8JBg+nXu1dU5VWKRo1SWLt2Tcl0bu5aUlJS\nIqyofBX9G9s/xtsBsWzIOTcL+GFviq0sTZo0ZcG8eWzevBnnHG++8TqpaS2jLivuZr7+Mv837h4e\nHj+R/Q/46c+2ZfNmNm/aBMDbb75GUlISR6fum/vvnOPyIYNJTW3J0GFXlbR/9eWXJb9PnvQCLVul\nR1FepemYlcWKFZ+yauVK8vPzmfjMBHr0rHqhussejnNum89CopTVKZuze59DTnYHaiYl0a59BoMG\nXxp1WXtl2GUXMm/2LNb98D057Vow7JrreXDsXeTnb+PCvj0BaN+hE7fedR/ff/ctF/XvRY0aNTi8\nYSPuvv+RiKv/+ebOmc2Ep54kvXUbcrKDweMbb76V556dwAdL3sfMaNqsGWPveyjiSuMrKSmJe8aO\n48we3SgqKuLCiwbRKr3qhao552Jb0Oxk4PdAc+BM59xaM7sIWOmcmxnjOo4ApjjnWlewzKXApQBN\nmjbt8PGnq2Kqb1/31f/27et+9kSDunWiLsGbWkn79lhYrHKyO7Jo0ULb3XIxPRpm1heYDHwLpAG1\nw1kHAMN/bpHlcc79wznX0TnX8dBDG8Rz1SISsVjjdwQwxDn3O6CwVPscICPuVYlIQoo1cI4Byrve\nfT1wcCwrMLOngXeAVDNba2YXx7htEUkQFZ0WL+0roAWwukx7DvB5LCtwzg3Yg7pEJAHF2sN5BPi7\nmXUguO7mcDPrD4wG/lFZxYlIYom1h3M7UJ9gzKYWMJtgLGesc+7vlVSbiCSYmALHBefO/2hmtwBt\nCHpGHzjnEusNKSJSqWLt4RTbRDCeA7AhzrWISIKL9TqcWmY2EvgRWB7efjSzO82sdsX3FhEJxNrD\nGQf0AoYRnNoGOA74G8Fp8cviX5qIJJpYA2cA0M85N71U2zIzywMmoMARkRjEelp8CztfgwOwCsiP\nWzUiktBiDZwHgb+UHq8xs1oE76N6sDIKE5HEs8tDKjN7tkxTd+A0M3svnG5P8Hk4MyqpNhFJMBWN\n4RSVmZ5aZvqNONciIgmuog/g0nufRCSuqsenA4lIlRDzlcZmNoDg9HhTfvoALgCcc63iXJeIJKBY\nrzS+EngI+IzgE/9eB9YAjYDnKq06EUkosR5S/Q641Dl3FVAAjHHOdQPuBfQ5oCISk1gDpwkwN/x9\nC1A3/H080C/eRYlIYoo1cL4m+DwcgC+ATuHvzYDdflK7iAjEHjhvAD3D3x8n+PS/l4Bngar3jeki\nUiXFepZqSPGyzrn7zGw9wecZvwbcV0m1iUiCifUT//Ip9SZN59zjBD0dEZGYVfReqpivrXHOLYtP\nOSKSyCrq4Swl+IaG8lg4r/hnzTjXJSIJqKLAaemtil0oLHJ8u2Fb1GV4UZ2+b3vysryoS/Dm121S\noi7Bi131TMqq6M2by+NUi4gIoDdviohHChwR8UaBIyLeKHBExJs9Chwz+4WZtQs/QF1EZI/E+nk4\nB5rZE8B6YBHBu8cxs3FmNqIS6xORBBJrD+cOIBXoDGwt1f4y0DfeRYlIYor1zZtnEXzz5jwzK32N\nzzLgqPiXJSKJKNYeTgPgm3LaD4xjLSKS4GINnEXAGaWmi3s5g4B34lqRiCSsWA+pRgDTzCwtvM/l\nZpYOnAicUEm1iUiCiamH45ybRRAshwG5QG9gE5DjnJtfeeWJSCKJ+XupnHOLgP6VWIuIJLiYAsfM\nDqhovnNuc3zKEZFEFmsPZyMVf+SFPoBLRHYr1sA5vcx0LSADGAzcENeKRCRhxfoh6jPKaZ5iZp8A\n5wNPxLUqEUlIe/tu8YXAyfEoREQS388OHDOrDVxOcJpcRGS3Yj1L9S07DhobcDDBd1VdUAl1iUgC\ninXQ+Poy09uBb4E5zrny3mMlIrKT3R5SmVkSUABMcs49HN7+zzn3wr4YNn++4jI6pDXltC4dStqm\nTnqerjmZHNngAJa8t6ik/a03X6PnyZ3p9quO9Dy5M3NmvRlBxXtv7Zo19Oh2ClkZremU2YYHxt0L\nwO233kzqUU3Iyc4kJzuTGdOnRVzpz5O/bSs3XNCT6849jWv6nsJzD929w/yp4x/mNx2asGHdDzu0\nf/dlLoO6pDL1iYd8lltp0o4+kqyMtmR3zCDn2KyoyynXbns4zrlCMxtHFfieqnjoc+5ALrx4CFdf\nPrikLbVlOg89NoG//HHoDsseUv+XPPLv5zg8uRHLP/qQC/qeybyln/suea8lJSVx28jRtM/IZMOG\nDRzfOYuTTzkVgMv/cCVXXPXHiCvcO7Vq12HEQ8+w3wEHUlhQwC0X96Zdzkkc3SaT77/K44O5s/hl\nw52/H+rJe26hXeeTIqi48rz0yusceuihUZexS7EOGs8H2lVmIb5kd+7CQYfU36GtxTFpND/6mJ2W\nbd22PYcnNwLgmLRWbN26lW3b9r0v5muYnEz7jEwA6tatS2paGnl5iTPWb2bsd0DwSSlFhYUUFRZi\nGADjx9zMgGEjMLMd7rPwjekc1qgJjZvv/HeXyhNr4IwD7jazIWaWZWatSt8qs8Cq4qXJ/6V12/bU\nqbNvf0Pm6tWrWLJ4MR2zsgF4+MFxHJfVnt9fdjHr1q2LuLqfb3tREdcN6Mbvuran9bG/okWbDBa+\nOYP6DRrS7Jgdn6JbN29i8uMP0vvSqyKqtnKYGT26d6Vzdkce+ec/oi6nXLEGzrNAc+ABYB7wQXhb\nGv7cLTNrYmZvmNkyM/vQzIb9nIKj8MnHyxh5y/Xcfve4qEvZKxs3bmTggL6MHD2GevXqMfiSISz5\naAWz571Lw4bJjBj+p6hL/Nlq1KzJHU/P4L6X5vPZ0sV88elHvPjoOPoM2flw8fmHx3D6eYNLekWJ\n4tU33mLewvd4YfI0/vHgA7z91qyoS9pJrGep4jF+Uwj80Tn3rpnVBRaZ2SvOuWVxWHel+TJvLZdd\n0J8x9/+TZkfuu5+mWlBQwPkD+tCv/3n0Ors3AIcdfnjJ/AsHDaZf715RlRc3B9Y9iFYdO7PozRl8\nm7eG6wZ0A+CHb75kxG9O55YnJvPZ0veY/9o0nr73djZvWI/VMGrV2Y/T+l8UbfF7KSUlGKc67LDD\nOPOss1m4YD5dfnV8xFXtqMLAMbNHgWHx+J5x59yXwJfh7xvM7CMgheBzkauk//3vR347oDfX3vg3\nOmZ3jrqcn805x+VDBpOa2pKhw346jPjqyy9pmJwMwORJL9CyVXpUJe6V9eu+p2ZSEgfWPYj8rVtY\nOm8WPS/8PQ++urhkmWE9j+PW8VOpe0h9bnzkPyXtzz88hv32P2CfD5tNmzaxfft26taty6ZNm3jt\n1Ve4bkTVe5vj7no4FwLDgQ3x3KiZHUHw5s955cy7FLgUIKVxk3huFoA/XHIBc2e/xbofvuPYNs25\n6tobOOiQQ7hp+NX88P13DDqvNy1bt2X8xMk88c+HWL3yM8bedQdj77oDgPETJ3Nog8PiXldlmjtn\nNhOeepL01m3IyQ4Gj2+8+Vaee3YCHyx5HzOjabNmjL1v3zw9/ON33/DQX69ie1ERzm0n+9QzyTz+\n1KjL8uqbr7/m3L5Bz7WwsJB+5w7gtG7dI65qZ+bcrj91wsy2Aw3jeb2Nmf0CmAnc5pz7T0XLtm3f\nwU1+bXa8Nl2l1T+wdtQleDN5WV7UJXjz6zY7n45PRDnHZvHuooW2u+ViGTSu6HNw9kj4jZ3PA//e\nXdiISOKJZdD4q7LXMJTlnNvtB3BZsJJHgI+cc2NiK09EEkksgXMp8GMctpUDDAQ+MLPi0by/OOf2\nzevpRWSPxRI4k+MxhuOcexvY7TGeiCSu3Y3hxG38RkRkd4GjHomIxE2Fh1TOub39CFIRkRIKFBHx\nRoEjIt4ocETEGwWOiHijwBERbxQ4IuKNAkdEvFHgiIg3ChwR8UaBIyLeKHBExBsFjoh4o8AREW8U\nOCLijQJHRLxR4IiINwocEfFGgSMi3ihwRMQbBY6IeBPL91JFJqmmVZvv3K6VVH2yv7p83zZAQVH1\n+KalWPey+jzLRSRyChwR8UaBIyLeKHBExBsFjoh4o8AREW8UOCLijQJHRLxR4IiINwocEfFGgSMi\n3ihwRMQbBY6IeKPAERFvFDgi4o0CR0S8UeCIiDcKHBHxRoEjIt4ocETEGwWOiHijwBERb6pt4Kxd\ns4Ye3U4hK6M1nTLb8MC4e3eYf9/fx1Bv/5p8/913EVVYeV6eMZ226amkp7Vg9KiRUZdT6YqKijg2\nK5PeZ58ZdSlxtXbNGnp2O4VOGa3JzmzDg+Fz+KLzz6VLdiZdsjNpk3oUXbIzI670J1X6e6kqU1JS\nEreNHE37jEw2bNjA8Z2zOPmUU0lr2Yq1a9bw2msv06RJ06jLjLuioiKuvOJypr70CimNG9Pl2Cx6\n9uxFy1atoi6t0tx/31jS0lqyfsP6qEuJq6SkJG4t9Rw+oXMWJ51yKo89OaFkmRHX/ol6Bx0UYZU7\nqrY9nIbJybTPCJK/bt26pKalkZeXC8B111zN3267EzOLssRKsWD+fJo3b8GRRx1F7dq16dv/XKZM\nnhR1WZVm7dq1TH9pGhcNujjqUuKuoucwgHOO/z4/kT79zo2qxJ1U28ApbfXqVSxZvJiOWdlMnTyJ\n5EYptGnbLuqyKkVeXi6NGzcpmU5JaUxubm4F99i3XfPHq7j1jjupUSOxn+qln8PF5sx+iwaHH07z\nFkdHWNmOvP0VzGw/M5tvZu+b2YdmdrOvbVdk48aNDBzQl5Gjx5CUlMRdo0Yy4sYqUZrspWlTp9Dg\nsAZkZnaIupRKVfwcvmP0GOrVq1fS/tyzE+jTt+r0bsDvGM424GTn3EYzqwW8bWYvOefmeqxhBwUF\nBZw/oA/9+p9Hr7N78+HSD1i9eiU5nTIAyM1dy6+O68gbb83l8IYNoyozrho1SmHt2jUl07m5a0lJ\nSczv+p47ZzZTp0xmxvSX2Lp1KxvWr2fQhQN59PHxUZcWNwUFBQws9RwuVlhYyORJ/2Xm7AURVrcz\nbz0cF9gYTtYKb5F907tzjsuHDCY1tSVDh10FQHrrNnz+xVcsXf45S5d/TkpKY956Z2HChA1Ax6ws\nVqz4lFUrV5Kfn8/EZybQo2evqMuqFLfcdgcrVq7h409X8sSTT3PCSScnVNg45xha5jlc7M3XX+WY\nY9JIadw4ourK5/XA1sxqmtli4BvgFefcvHKWudTMFprZwu++/bbSapk7ZzYTnnqSWTPfICc7k5zs\nTGZMn1Zp26sqkpKSuGfsOM7s0Y32bVpyTt9+tEpPj7os+RlKP4eLT4O/HD6Hn5/4DOf06x9xhTsz\n5/x3MszsYOC/wB+cc0t3tVxmh45u5uz5/gqLUK2kxB7ULC2K51xUCoqqx76ekNOJ9xYt3O1p3Uie\n5c65H4E3gO5RbF9EouHzLFWDsGeDme0PdAU+9rV9EYmez7NUycDjZlaTIOiedc5N8bh9EYmYt8Bx\nzi0BMnwKGdceAAAHVUlEQVRtT0SqnuozUikikVPgiIg3ChwR8UaBIyLeKHBExBsFjoh4o8AREW8U\nOCLijQJHRLxR4IiINwocEfFGgSMi3ihwRMQbBY6IeKPAERFvFDgi4o0CR0S8UeCIiDcKHBHxRoEj\nIt4ocETEGwWOiHijwBERbyL5bvFYmdm3wGrPmz0U+M7zNqNSXfa1uuwnRLevzZxzDXa3UJUOnCiY\n2ULnXMeo6/ChuuxrddlPqPr7qkMqEfFGgSMi3ihwdvaPqAvwqLrsa3XZT6ji+6oxHBHxRj0cEfFG\ngSMi3ihwRMQbBY6IeJMUdQFRM7M04CwgJWzKBV50zn0UXVWyN8K/aQowzzm3sVR7d+fc9Ogqiz8z\n6wQ459wCM2sFdAc+ds5Ni7i0clXrHo6ZXQtMAAyYH94MeNrMhkdZm09m9tuoa4gXM7sCmAT8AVhq\nZmeVmn17NFVVDjP7K3Av8KCZ3QGMAw4EhpvZiEiL24VqfVrczD4B0p1zBWXaawMfOueOjqYyv8zs\nC+dc06jriAcz+wA4zjm30cyOAJ4DxjvnxprZe865jEgLjKNwX9sDdYCvgMbOufVmtj9B765tpAWW\no7ofUm0HGrHzG0STw3kJw8yW7GoWcLjPWipZjeLDKOfcKjM7EXjOzJoR7GsiKXTOFQGbzewz59x6\nAOfcFjOrks/f6h44VwKvmdmnwJqwrSnQAhgaWVWV43CgG7CuTLsBc/yXU2m+NrP2zrnFAGFPpyfw\nKNAm2tLiLt/MDnDObQY6FDea2UFU0X+Y1fqQCsDMagCd2HHQeEH4nyNhmNkjwL+cc2+XM+8p59x5\nEZQVd2bWmOA//1flzMtxzs2OoKxKYWZ1nHPbymk/FEh2zn0QQVkVqvaBIyL+VOuzVCLilwJHRLxR\n4MhOzGypmd1UanqVmf0pgjo6mpkLT2/vapk3zWzcHqzzxHCdh+5lbY+Z2ZS9WUd1pMDZB4RPbhfe\nCszsczO7y8wO9FRCFvBALAua2UVmtnH3S0p1VN1Pi+9LXgUGArWAXwH/BA4Afl/ewmZWq+wFjT+X\nc+7beKxHRD2cfcc259xXzrk1zrmngCeBs2GHw4QzzGy+meUTXHODmZ1pZovMbKuZrTSz28IrqQnn\nH2Zmk8xsi5mtNrNBZTdc9pDKzA4yswfN7MtwvR+ZWf/wIrt/AQeW6pHdFN6ntpndaWZrzWyzmS0w\ns25lttPdzD4O1/kWcMyePkhmdn647g1m9o2ZTTSzlHIWPdbMFofbWmRmHcqsp7OZzQxrzQ33t96e\n1iM7UuDsu7YSXNJe2p3A9UAaMC98Qf+b4D026cAgoA87vqfoMYILHU8lCLALgCN2tVEzM2AacALw\nW6AlMAzYRnAB4ZXAZoKrtZOBu8K7/iu8z3lAa+BxYLKZtQvX2wR4AXiF4HL9+4BRsT4YpdQG/gq0\nA3oSfG3K0+UsdxdwLdAR+ByYYmYHhLW0AV4GXgzX0zus6dGfUY+U5pzTrYrfCEJhSqnpTsD3wDPh\n9ImAA84pc79ZwA1l2s4GNhJcYXxMeL+cUvObAUXATaXaVgF/Cn/vSnAVa8td1HoRsLFMW/PwPk3L\ntL8APBD+fjvwCeG1YWHb9WF9R1Tw2LwJjKtgflq4jsZlHqvflFrmF8CPwOBw+gngkTLraR/e77Dy\n/ia6xXbTGM6+o3s4GJtEMI5T/I7o0haWme4AdArfFV+sBrA/0JCgd7Kd4F3yADjnVptZXgV1ZABf\nuj37+I5MgoBbFnSQStQBXg9/bwnMdeGrOfTOHmwDADPLJOjhtAfq89P7p5oCa8tbtwve/vAB0Cps\n6gC0MLP+pVcd/mwOfLOndUlAgbPvmAVcChQAea78AeFNZaZrADcDE8tZtvRAcGVfbl4j3EYWQf2l\nbYnXRsKzdjP4aYD9G4JDqrcIDrViVYNgUP6ecubl7mWZ1ZoCZ9+x2Tm3Yg/v8y6Qtqv7mdnHBC+u\nToRv4DSzpgTvoN+V94BkM2u5i15OPlCznPsY0NA598Yu1vsRcI6ZWalezrEV1FGeNIKA+YtzbiWA\nmfXexbLHEozdFAdVa4JDKQget/Sf8XjLbmjQOLHdApxnZreYWWszSzOzPmY2CsA5txyYDjxsZseZ\nWXuCsYmKeh2vAfOA582sm5kdaWZdzezscP4qYL+w7dDw3cyfEAxePxZu/6jwor4/lQqEhwgGq/9u\nZqlm1gcYsof7+wXB4PXQcBs9gL/tYtnrwxrTCQaD84Gnwnl3EhyKPmRmGWbWwsx6mtnDe1iPlKHA\nSWDOuRlAD+AkfvpEw+EEL8xiFwErCcZSJhO86FZVsM7twOnAbIJT8x8BYwkPWZxzcwjC42mCw7Zr\nwrv+luBM1SjgY2AKcDzhZxE5574gOBvUHXgfuCqsdU/291vgQoKB8WUEYzlX72Lx4cDdBL2Zo4Ge\nzrlN4XqWhLUdAcwM67kD+HpP6pGd6d3iIuKNejgi4o0CR0S8UeCIiDcKHBHxRoEjIt4ocETEGwWO\niHijwBERb/4fI6fF+cFYhPUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2099007af28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load weights into new model\n",
    "model.load_weights(\"C:\\jupyter\\weights.bestv6v6.hdf5\")\n",
    "print(\"Loaded model from disk\")\n",
    " \n",
    "# evaluate loaded model on test data\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "score = model.evaluate(X_test, y_1Hot_test, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], score[1]*100))\n",
    "\n",
    "y_true, y_pred = y_1Hot_test.astype('int'), model.predict(X_test)\n",
    "y_pred = y_pred.round().astype('int')\n",
    "\n",
    "# from categorial to lable indexing\n",
    "y_pred = y_pred.argmax(1)\n",
    "y_true = y_true.argmax(1)\n",
    "\n",
    "print(classification_report(y_true, y_pred))\n",
    "plot_confusion_matrix(y_true, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n",
      "acc: 86.17%\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.96      0.91      1003\n",
      "          1       0.91      0.73      0.81       162\n",
      "          2       0.82      0.74      0.78       486\n",
      "          3       0.74      0.53      0.62        55\n",
      "\n",
      "avg / total       0.86      0.86      0.86      1706\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1wAAANqCAYAAACZxkp0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x19f9c332fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load weights into new model\n",
    "model.load_weights(\"C:\\jupyter\\weights.bestv6v4.hdf5\")\n",
    "print(\"Loaded model from disk\")\n",
    " \n",
    "# evaluate loaded model on test data\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "score = model.evaluate(X_test, y_1Hot_test, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], score[1]*100))\n",
    "\n",
    "y_true, y_pred = y_1Hot_test.astype('int'), model.predict(X_test)\n",
    "y_pred = y_pred.round().astype('int')\n",
    "\n",
    "# from categorial to lable indexing\n",
    "y_pred = y_pred.argmax(1)\n",
    "y_true = y_true.argmax(1)\n",
    "\n",
    "print(classification_report(y_true, y_pred))\n",
    "plot_confusion_matrix(y_true, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load weights into new model\n",
    "model.load_weights(\"C:\\jupyter\\weights.bestv4v3.hdf5\")\n",
    "print(\"Loaded model from disk\")\n",
    " \n",
    "# evaluate loaded model on test data\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "score = model.evaluate(X_test, y_1Hot_test, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], score[1]*100))\n",
    "\n",
    "y_true, y_pred = y_1Hot_test.astype('int'), model.predict(X_test)\n",
    "y_pred = y_pred.round().astype('int')\n",
    "\n",
    "# from categorial to lable indexing\n",
    "y_pred = y_pred.argmax(1)\n",
    "y_true = y_true.argmax(1)\n",
    "\n",
    "print(classification_report(y_true, y_pred))\n",
    "plot_confusion_matrix(y_true, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load weights into new model\n",
    "model.load_weights(\"C:\\jupyter\\weights_v4v2_layer_cnn.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    " \n",
    "# evaluate loaded model on test data\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "score = model.evaluate(X_test, y_1Hot_test, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], score[1]*100))\n",
    "\n",
    "y_true, y_pred = y_1Hot_test.astype('int'), model.predict(X_test)\n",
    "y_pred = y_pred.round().astype('int')\n",
    "\n",
    "# from categorial to lable indexing\n",
    "y_pred = y_pred.argmax(1)\n",
    "y_true = y_true.argmax(1)\n",
    "\n",
    "print(classification_report(y_true, y_pred))\n",
    "plot_confusion_matrix(y_true, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# evaluate the model\n",
    "trainScore = model.evaluate(X_train, y_1Hot_train, verbose=0)\n",
    "print(\"TrainScore: \\n%s: %.2f%%\" % (model.metrics_names[1], trainScore[1]*100))\n",
    "testScore = model.evaluate(X_test, y_1Hot_test, verbose=0)\n",
    "print(\"TestScore: \\n%s: %.2f%%\" % (model.metrics_names[1], testScore[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "y_true, y_pred = y_1Hot_test.astype('int'), model.predict(X_test)\n",
    "y_pred = y_pred.round().astype('int')\n",
    "\n",
    "# from categorial to lable indexing\n",
    "y_pred = y_pred.argmax(1)\n",
    "y_true = y_true.argmax(1)\n",
    "\n",
    "print(classification_report(y_true, y_pred))\n",
    "plot_confusion_matrix(y_true, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.layers[30].output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "def get_activations(model, layer, X_batch):\n",
    "    get_activations = K.function([model.layers[0].input, K.learning_phase()], model.layers[layer].output)\n",
    "    activations = get_activations([X_batch,0])\n",
    "    return activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "get_3rd_layer_output = K.function([model.layers[0].input, K.learning_phase()],\n",
    "                                  [model.layers[29].output])\n",
    "\n",
    "# # output in test mode = 0\n",
    "# layer_output = get_3rd_layer_output([X_train, 0])[0]\n",
    "\n",
    "# output in train mode = 1\n",
    "\n",
    "start = 0\n",
    "while start <= len(X_train):\n",
    "    end = start + 10\n",
    "    layer_output = get_3rd_layer_output([X_train[start : end ], 1])[0]\n",
    "    start = end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layer_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l0 = np.squeeze(layer_output, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l1 = l0[0].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l1.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c_batch = np.expand_dims(X_train[1], axis=0)\n",
    "c_1 = model.predict(c_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vis_c(cb):\n",
    "    cv = np.squeeze(cb, axis=0)\n",
    "    print(cv.shape)\n",
    "    plt.show(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X2 = scaled_X.reshape(scaled_X.shape[0], scaled_X.shape[1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Get output from layer 40\n",
    "\n",
    "from keras.models import Model\n",
    "\n",
    "print (\"First layer:\")\n",
    "intermediate_layer_model = Model(input=model.input,output=model.layers[40].output)\n",
    "l0 = intermediate_layer_model.predict(X2)\n",
    "\n",
    "mast = []\n",
    "for i in range(0,8528):\n",
    "    l1 = l0[i].flatten()\n",
    "    y0 = np.asarray([y[i]]).astype(\"int\")\n",
    "    ind = np.asarray([index[i]])\n",
    "    abc = np.concatenate([ind, y0, l1])\n",
    "    mast.append(abc)\n",
    "    \n",
    "mPd = pd.DataFrame(mast)\n",
    "mPd.to_csv('output_cnnv2.csv', sep=',', header=False, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
